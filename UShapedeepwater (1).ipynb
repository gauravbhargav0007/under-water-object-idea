{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UShapedeepwater.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#from utility.ptcolor import rgb2lab\n",
        "#from utility.Qnt import quantAB,quantL\n",
        "import torch\n",
        "from torch.nn import functional\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class lab_Loss(nn.Module):\n",
        "    def __init__(self, alpha=1,weight=1,levels=7,vmin=-80,vmax=80):\n",
        "        super(lab_Loss, self).__init__()\n",
        "        self.alpha=alpha\n",
        "        self.weight=weight\n",
        "        self.levels=levels\n",
        "        self.vmin=vmin\n",
        "        self.vmax=vmax\n",
        "\n",
        "    def Hist_2_Dist_L(self,img, tab,alpha):\n",
        "        img_dist=((img.unsqueeze(1)-tab)**2)\n",
        "        p=functional.softmax(-alpha*img_dist,dim=1)\n",
        "        return p\n",
        "\n",
        "    def Hist_2_Dist_AB(self,img,tab,alpha):\n",
        "        img_dist=((img.unsqueeze(1)-tab)**2).sum(2)\n",
        "        p = torch.nn.functional.softmax(-alpha*img_dist, dim=1)\n",
        "        return p\n",
        "\n",
        "    def loss_ab(self,img,gt,alpha,tab,levels):\n",
        "        p= self.Hist_2_Dist_AB(img, tab,alpha).cuda()\n",
        "        q= self.Hist_2_Dist_AB(gt,tab,alpha).cuda()\n",
        "        p = torch.clamp(p, 0.001, 0.999)\n",
        "        loss = -(q*torch.log(p)).sum([1,2,3]).mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,img,gt):\n",
        "\t    tab=quantAB(self.levels,self.vmin,self.vmax).cuda()\n",
        "\t    lab_img=torch.clamp(rgb2lab(img),self.vmin,self.vmax)\n",
        "\t    lab_gt=torch.clamp(rgb2lab(gt),self.vmin,self.vmax)\n",
        "\n",
        "\t    loss_l=torch.abs(lab_img[:,0,:,:]-lab_gt[:,0,:,:]).mean()\n",
        "\t    loss_AB=self.loss_ab(lab_img[:,1:,:,:],lab_gt[:,1:,:,:],self.alpha,tab,self.levels)\n",
        "\t    loss=loss_l+self.weight*loss_AB\n",
        "\t    #return (loss,loss_l,loss_AB)\n",
        "\t    return loss"
      ],
      "metadata": {
        "id": "xvzC9V4jD8Xo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#from utilities import ptcolor as ptcolor\n",
        "import torch.nn as nn\n",
        "\n",
        "class lch_Loss(nn.Module):\n",
        "    def __init__(self, weightC=1,weightH=1,levels=4,eps=0.01,weight=None):\n",
        "        super(lch_Loss, self).__init__()\n",
        "        self.weightC=weightC\n",
        "        self.weightH=weightH\n",
        "        self.levels=levels\n",
        "        self.eps=eps\n",
        "        self.weight=weight\n",
        "\n",
        "\n",
        "    def hue_to_distribution(self,h, levels, eps=0.0):\n",
        "        h = h * (levels / 360.0)\n",
        "        a = torch.arange(levels).float().to(h.device)\n",
        "        a = a.view(1, levels, 1, 1)\n",
        "        h=h.unsqueeze(1)\n",
        "        p = torch.relu(1 - torch.abs(h - a))\n",
        "        p = p + (a == 0.0).float() * p[:, -1:, :, :]\n",
        "        p = (p + torch.ones_like(p) * eps) / (1.0 + levels * eps)\n",
        "        return p\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,img,gt):\n",
        "        img_lch= ptcolor.rgb2lch(img)\n",
        "        gt_lch= ptcolor.rgb2lch(gt)\n",
        "        loss_L=torch.mean(torch.abs(img_lch[:,0,:,:]-gt_lch[:,0,:,:]))\n",
        "        loss_C=torch.mean(torch.abs(img_lch[:,1,:,:]-gt_lch[:,1,:,:]))\n",
        "        img_H_Dist=torch.clamp(self.hue_to_distribution(img_lch[:,2,:,:],self.levels,self.eps),0.001, 0.999)\n",
        "        gt_H_Dist =torch.clamp(self.hue_to_distribution(gt_lch[:, 2, :, :], self.levels),0.001, 0.999)\n",
        "        if self.weight is None:\n",
        "            loss_H = torch.mean(-torch.mul(gt_H_Dist, torch.log(img_H_Dist)))\n",
        "        else:\n",
        "            loss_H = -(gt_lch[:,1,:,:]*(gt_H_Dist*torch.log(img_H_Dist)).sum(1,keepdim=True)).mean()\n",
        "        loss=loss_L+self.weightC*loss_C+self.weightH*loss_H\n",
        "        #return(loss,loss_L,loss_C,loss_H)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "K8jNbwICE0-a"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import copy\n",
        "import logging\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.nn import Dropout, Softmax, Conv2d, LayerNorm\n",
        "from torch.nn.modules.utils import _pair\n",
        "\n",
        "\n",
        "#KV_size = 480\n",
        "#transformer.num_heads  = 4\n",
        "#transformer.num_layers = 4\n",
        "#expand_ratio           = 4\n",
        "\n",
        "class Channel_Embeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from patch, position embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, patchsize, img_size, in_channels):\n",
        "        super().__init__()\n",
        "        img_size = _pair(img_size)\n",
        "        patch_size = _pair(patchsize)\n",
        "        n_patches = (img_size[0] // patch_size[0]) * (img_size[1] // patch_size[1])\n",
        "\n",
        "        self.patch_embeddings = Conv2d(in_channels=in_channels,\n",
        "                                       out_channels=in_channels,\n",
        "                                       kernel_size=patch_size,\n",
        "                                       stride=patch_size)\n",
        "        self.position_embeddings = nn.Parameter(torch.zeros(1, n_patches, in_channels))\n",
        "        self.dropout = Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x is None:\n",
        "            return None\n",
        "        x = self.patch_embeddings(x)  # (B, hidden，n_patches^(1/2), n_patches^(1/2))\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(-1, -2)  # (B, n_patches, hidden)\n",
        "        embeddings = x + self.position_embeddings\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class Reconstruct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, scale_factor):\n",
        "        super(Reconstruct, self).__init__()\n",
        "        if kernel_size == 3:\n",
        "            padding = 1\n",
        "        else:\n",
        "            padding = 0\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels,kernel_size=kernel_size, padding=padding)\n",
        "        self.norm = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x is None:\n",
        "            return None\n",
        "\n",
        "        # reshape from (B, n_patch, hidden) to (B, h, w, hidden)\n",
        "        B, n_patch, hidden = x.size()  \n",
        "        h, w = int(np.sqrt(n_patch)), int(np.sqrt(n_patch))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = x.contiguous().view(B, hidden, h, w)\n",
        "        x = nn.Upsample(scale_factor=self.scale_factor)(x)\n",
        "\n",
        "        out = self.conv(x)\n",
        "        out = self.norm(out)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "class Attention_org(nn.Module):\n",
        "    def __init__(self, vis,channel_num, KV_size=480, num_heads=4):\n",
        "        super(Attention_org, self).__init__()\n",
        "        self.vis = vis\n",
        "        self.KV_size = KV_size\n",
        "        self.channel_num = channel_num\n",
        "        self.num_attention_heads = num_heads\n",
        "\n",
        "        self.query1 = nn.ModuleList()\n",
        "        self.query2 = nn.ModuleList()\n",
        "        self.query3 = nn.ModuleList()\n",
        "        self.query4 = nn.ModuleList()\n",
        "        self.key = nn.ModuleList()\n",
        "        self.value = nn.ModuleList()\n",
        "\n",
        "        for _ in range(num_heads):\n",
        "            query1 = nn.Linear(channel_num[0], channel_num[0], bias=False)\n",
        "            query2 = nn.Linear(channel_num[1], channel_num[1], bias=False)\n",
        "            query3 = nn.Linear(channel_num[2], channel_num[2], bias=False)\n",
        "            query4 = nn.Linear(channel_num[3], channel_num[3], bias=False)\n",
        "            key = nn.Linear( self.KV_size,  self.KV_size, bias=False)\n",
        "            value = nn.Linear(self.KV_size,  self.KV_size, bias=False)\n",
        "            self.query1.append(copy.deepcopy(query1))\n",
        "            self.query2.append(copy.deepcopy(query2))\n",
        "            self.query3.append(copy.deepcopy(query3))\n",
        "            self.query4.append(copy.deepcopy(query4))\n",
        "            self.key.append(copy.deepcopy(key))\n",
        "            self.value.append(copy.deepcopy(value))\n",
        "        self.psi = nn.InstanceNorm2d(self.num_attention_heads)\n",
        "        self.softmax = Softmax(dim=3)\n",
        "        self.out1 = nn.Linear(channel_num[0], channel_num[0], bias=False)\n",
        "        self.out2 = nn.Linear(channel_num[1], channel_num[1], bias=False)\n",
        "        self.out3 = nn.Linear(channel_num[2], channel_num[2], bias=False)\n",
        "        self.out4 = nn.Linear(channel_num[3], channel_num[3], bias=False)\n",
        "        self.attn_dropout = Dropout(0.1)\n",
        "        self.proj_dropout = Dropout(0.1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, emb1,emb2,emb3,emb4, emb_all):\n",
        "        multi_head_Q1_list = []\n",
        "        multi_head_Q2_list = []\n",
        "        multi_head_Q3_list = []\n",
        "        multi_head_Q4_list = []\n",
        "        multi_head_K_list = []\n",
        "        multi_head_V_list = []\n",
        "        if emb1 is not None:\n",
        "            for query1 in self.query1:\n",
        "                Q1 = query1(emb1)\n",
        "                multi_head_Q1_list.append(Q1)\n",
        "        if emb2 is not None:\n",
        "            for query2 in self.query2:\n",
        "                Q2 = query2(emb2)\n",
        "                multi_head_Q2_list.append(Q2)\n",
        "        if emb3 is not None:\n",
        "            for query3 in self.query3:\n",
        "                Q3 = query3(emb3)\n",
        "                multi_head_Q3_list.append(Q3)\n",
        "        if emb4 is not None:\n",
        "            for query4 in self.query4:\n",
        "                Q4 = query4(emb4)\n",
        "                multi_head_Q4_list.append(Q4)\n",
        "        for key in self.key:\n",
        "            K = key(emb_all)\n",
        "            multi_head_K_list.append(K)\n",
        "        for value in self.value:\n",
        "            V = value(emb_all)\n",
        "            multi_head_V_list.append(V)\n",
        "        # print(len(multi_head_Q4_list))\n",
        "\n",
        "        multi_head_Q1 = torch.stack(multi_head_Q1_list, dim=1) if emb1 is not None else None\n",
        "        multi_head_Q2 = torch.stack(multi_head_Q2_list, dim=1) if emb2 is not None else None\n",
        "        multi_head_Q3 = torch.stack(multi_head_Q3_list, dim=1) if emb3 is not None else None\n",
        "        multi_head_Q4 = torch.stack(multi_head_Q4_list, dim=1) if emb4 is not None else None\n",
        "        multi_head_K = torch.stack(multi_head_K_list, dim=1)\n",
        "        multi_head_V = torch.stack(multi_head_V_list, dim=1)\n",
        "\n",
        "        multi_head_Q1 = multi_head_Q1.transpose(-1, -2) if emb1 is not None else None\n",
        "        multi_head_Q2 = multi_head_Q2.transpose(-1, -2) if emb2 is not None else None\n",
        "        multi_head_Q3 = multi_head_Q3.transpose(-1, -2) if emb3 is not None else None\n",
        "        multi_head_Q4 = multi_head_Q4.transpose(-1, -2) if emb4 is not None else None\n",
        "\n",
        "        attention_scores1 = torch.matmul(multi_head_Q1, multi_head_K) if emb1 is not None else None\n",
        "        attention_scores2 = torch.matmul(multi_head_Q2, multi_head_K) if emb2 is not None else None\n",
        "        attention_scores3 = torch.matmul(multi_head_Q3, multi_head_K) if emb3 is not None else None\n",
        "        attention_scores4 = torch.matmul(multi_head_Q4, multi_head_K) if emb4 is not None else None\n",
        "\n",
        "        attention_scores1 = attention_scores1 / math.sqrt(self.KV_size) if emb1 is not None else None\n",
        "        attention_scores2 = attention_scores2 / math.sqrt(self.KV_size) if emb2 is not None else None\n",
        "        attention_scores3 = attention_scores3 / math.sqrt(self.KV_size) if emb3 is not None else None\n",
        "        attention_scores4 = attention_scores4 / math.sqrt(self.KV_size) if emb4 is not None else None\n",
        "\n",
        "        attention_probs1 = self.softmax(self.psi(attention_scores1)) if emb1 is not None else None\n",
        "        attention_probs2 = self.softmax(self.psi(attention_scores2)) if emb2 is not None else None\n",
        "        attention_probs3 = self.softmax(self.psi(attention_scores3)) if emb3 is not None else None\n",
        "        attention_probs4 = self.softmax(self.psi(attention_scores4)) if emb4 is not None else None\n",
        "        # print(attention_probs4.size())\n",
        "\n",
        "        if self.vis:\n",
        "            weights =  []\n",
        "            weights.append(attention_probs1.mean(1))\n",
        "            weights.append(attention_probs2.mean(1))\n",
        "            weights.append(attention_probs3.mean(1))\n",
        "            weights.append(attention_probs4.mean(1))\n",
        "        else: weights=None\n",
        "\n",
        "        attention_probs1 = self.attn_dropout(attention_probs1) if emb1 is not None else None\n",
        "        attention_probs2 = self.attn_dropout(attention_probs2) if emb2 is not None else None\n",
        "        attention_probs3 = self.attn_dropout(attention_probs3) if emb3 is not None else None\n",
        "        attention_probs4 = self.attn_dropout(attention_probs4) if emb4 is not None else None\n",
        "\n",
        "        multi_head_V = multi_head_V.transpose(-1, -2)\n",
        "        context_layer1 = torch.matmul(attention_probs1, multi_head_V) if emb1 is not None else None\n",
        "        context_layer2 = torch.matmul(attention_probs2, multi_head_V) if emb2 is not None else None\n",
        "        context_layer3 = torch.matmul(attention_probs3, multi_head_V) if emb3 is not None else None\n",
        "        context_layer4 = torch.matmul(attention_probs4, multi_head_V) if emb4 is not None else None\n",
        "\n",
        "        context_layer1 = context_layer1.permute(0, 3, 2, 1).contiguous() if emb1 is not None else None\n",
        "        context_layer2 = context_layer2.permute(0, 3, 2, 1).contiguous() if emb2 is not None else None\n",
        "        context_layer3 = context_layer3.permute(0, 3, 2, 1).contiguous() if emb3 is not None else None\n",
        "        context_layer4 = context_layer4.permute(0, 3, 2, 1).contiguous() if emb4 is not None else None\n",
        "        context_layer1 = context_layer1.mean(dim=3) if emb1 is not None else None\n",
        "        context_layer2 = context_layer2.mean(dim=3) if emb2 is not None else None\n",
        "        context_layer3 = context_layer3.mean(dim=3) if emb3 is not None else None\n",
        "        context_layer4 = context_layer4.mean(dim=3) if emb4 is not None else None\n",
        "\n",
        "        O1 = self.out1(context_layer1) if emb1 is not None else None\n",
        "        O2 = self.out2(context_layer2) if emb2 is not None else None\n",
        "        O3 = self.out3(context_layer3) if emb3 is not None else None\n",
        "        O4 = self.out4(context_layer4) if emb4 is not None else None\n",
        "        O1 = self.proj_dropout(O1) if emb1 is not None else None\n",
        "        O2 = self.proj_dropout(O2) if emb2 is not None else None\n",
        "        O3 = self.proj_dropout(O3) if emb3 is not None else None\n",
        "        O4 = self.proj_dropout(O4) if emb4 is not None else None\n",
        "        return O1,O2,O3,O4, weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_channel, mlp_channel):\n",
        "        super(Mlp, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_channel, mlp_channel)\n",
        "        self.fc2 = nn.Linear(mlp_channel, in_channel)\n",
        "        self.act_fn = nn.GELU()\n",
        "        self.dropout = Dropout(0.0)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.normal_(self.fc1.bias, std=1e-6)\n",
        "        nn.init.normal_(self.fc2.bias, std=1e-6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class Block_ViT(nn.Module):\n",
        "    def __init__(self, vis, channel_num, expand_ratio=4,KV_size=480):\n",
        "        super(Block_ViT, self).__init__()\n",
        "        expand_ratio = 4\n",
        "        self.attn_norm1 = LayerNorm(channel_num[0],eps=1e-6)\n",
        "        self.attn_norm2 = LayerNorm(channel_num[1],eps=1e-6)\n",
        "        self.attn_norm3 = LayerNorm(channel_num[2],eps=1e-6)\n",
        "        self.attn_norm4 = LayerNorm(channel_num[3],eps=1e-6)\n",
        "        self.attn_norm =  LayerNorm(KV_size,eps=1e-6)\n",
        "        self.channel_attn = Attention_org(vis, channel_num)\n",
        "\n",
        "        self.ffn_norm1 = LayerNorm(channel_num[0],eps=1e-6)\n",
        "        self.ffn_norm2 = LayerNorm(channel_num[1],eps=1e-6)\n",
        "        self.ffn_norm3 = LayerNorm(channel_num[2],eps=1e-6)\n",
        "        self.ffn_norm4 = LayerNorm(channel_num[3],eps=1e-6)\n",
        "        self.ffn1 = Mlp(channel_num[0],channel_num[0]*expand_ratio)\n",
        "        self.ffn2 = Mlp(channel_num[1],channel_num[1]*expand_ratio)\n",
        "        self.ffn3 = Mlp(channel_num[2],channel_num[2]*expand_ratio)\n",
        "        self.ffn4 = Mlp(channel_num[3],channel_num[3]*expand_ratio)\n",
        "\n",
        "\n",
        "    def forward(self, emb1,emb2,emb3,emb4):\n",
        "        embcat = []\n",
        "        org1 = emb1\n",
        "        org2 = emb2\n",
        "        org3 = emb3\n",
        "        org4 = emb4\n",
        "        for i in range(4):\n",
        "            var_name = \"emb\"+str(i+1)  #emb1,emb2,emb3,emb4\n",
        "            tmp_var = locals()[var_name]\n",
        "            if tmp_var is not None:\n",
        "                embcat.append(tmp_var)\n",
        "\n",
        "        emb_all = torch.cat(embcat,dim=2)\n",
        "        cx1 = self.attn_norm1(emb1) if emb1 is not None else None\n",
        "        cx2 = self.attn_norm2(emb2) if emb2 is not None else None\n",
        "        cx3 = self.attn_norm3(emb3) if emb3 is not None else None\n",
        "        cx4 = self.attn_norm4(emb4) if emb4 is not None else None\n",
        "        emb_all = self.attn_norm(emb_all)\n",
        "        cx1,cx2,cx3,cx4, weights = self.channel_attn(cx1,cx2,cx3,cx4,emb_all)\n",
        "        #残差\n",
        "        cx1 = org1 + cx1 if emb1 is not None else None\n",
        "        cx2 = org2 + cx2 if emb2 is not None else None\n",
        "        cx3 = org3 + cx3 if emb3 is not None else None\n",
        "        cx4 = org4 + cx4 if emb4 is not None else None\n",
        "\n",
        "        org1 = cx1\n",
        "        org2 = cx2\n",
        "        org3 = cx3\n",
        "        org4 = cx4\n",
        "        x1 = self.ffn_norm1(cx1) if emb1 is not None else None\n",
        "        x2 = self.ffn_norm2(cx2) if emb2 is not None else None\n",
        "        x3 = self.ffn_norm3(cx3) if emb3 is not None else None\n",
        "        x4 = self.ffn_norm4(cx4) if emb4 is not None else None\n",
        "        x1 = self.ffn1(x1) if emb1 is not None else None\n",
        "        x2 = self.ffn2(x2) if emb2 is not None else None\n",
        "        x3 = self.ffn3(x3) if emb3 is not None else None\n",
        "        x4 = self.ffn4(x4) if emb4 is not None else None\n",
        "        #残差\n",
        "        x1 = x1 + org1 if emb1 is not None else None\n",
        "        x2 = x2 + org2 if emb2 is not None else None\n",
        "        x3 = x3 + org3 if emb3 is not None else None\n",
        "        x4 = x4 + org4 if emb4 is not None else None\n",
        "\n",
        "        return x1, x2, x3, x4, weights\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vis, channel_num, num_layers=4):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.vis = vis\n",
        "        self.layer = nn.ModuleList()\n",
        "        self.encoder_norm1 = LayerNorm(channel_num[0],eps=1e-6)\n",
        "        self.encoder_norm2 = LayerNorm(channel_num[1],eps=1e-6)\n",
        "        self.encoder_norm3 = LayerNorm(channel_num[2],eps=1e-6)\n",
        "        self.encoder_norm4 = LayerNorm(channel_num[3],eps=1e-6)\n",
        "        for _ in range(num_layers):\n",
        "            layer = Block_ViT(vis, channel_num)\n",
        "            self.layer.append(copy.deepcopy(layer))\n",
        "\n",
        "    def forward(self, emb1,emb2,emb3,emb4):\n",
        "        attn_weights = []\n",
        "        for layer_block in self.layer:\n",
        "            emb1,emb2,emb3,emb4, weights = layer_block(emb1,emb2,emb3,emb4)\n",
        "            if self.vis:\n",
        "                attn_weights.append(weights)\n",
        "        emb1 = self.encoder_norm1(emb1) if emb1 is not None else None\n",
        "        emb2 = self.encoder_norm2(emb2) if emb2 is not None else None\n",
        "        emb3 = self.encoder_norm3(emb3) if emb3 is not None else None\n",
        "        emb4 = self.encoder_norm4(emb4) if emb4 is not None else None\n",
        "        return emb1,emb2,emb3,emb4, attn_weights\n",
        "\n",
        "\n",
        "class ChannelTransformer(nn.Module):\n",
        "    def __init__(self,  vis=False, img_size=256, channel_num=[64, 128, 256, 512], patchSize=[32, 16, 8, 4]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patchSize_1 = patchSize[0]\n",
        "        self.patchSize_2 = patchSize[1]\n",
        "        self.patchSize_3 = patchSize[2]\n",
        "        self.patchSize_4 = patchSize[3]\n",
        "        self.embeddings_1 = Channel_Embeddings(self.patchSize_1, img_size=img_size,    in_channels=channel_num[0])\n",
        "        self.embeddings_2 = Channel_Embeddings(self.patchSize_2, img_size=img_size//2, in_channels=channel_num[1])\n",
        "        self.embeddings_3 = Channel_Embeddings(self.patchSize_3, img_size=img_size//4, in_channels=channel_num[2])\n",
        "        self.embeddings_4 = Channel_Embeddings(self.patchSize_4, img_size=img_size//8, in_channels=channel_num[3])\n",
        "        self.encoder = Encoder( vis, channel_num)\n",
        "\n",
        "        self.reconstruct_1 = Reconstruct(channel_num[0], channel_num[0], kernel_size=1,scale_factor=(self.patchSize_1,self.patchSize_1))\n",
        "        self.reconstruct_2 = Reconstruct(channel_num[1], channel_num[1], kernel_size=1,scale_factor=(self.patchSize_2,self.patchSize_2))\n",
        "        self.reconstruct_3 = Reconstruct(channel_num[2], channel_num[2], kernel_size=1,scale_factor=(self.patchSize_3,self.patchSize_3))\n",
        "        self.reconstruct_4 = Reconstruct(channel_num[3], channel_num[3], kernel_size=1,scale_factor=(self.patchSize_4,self.patchSize_4))\n",
        "\n",
        "    def forward(self,en1,en2,en3,en4):\n",
        "\n",
        "        emb1 = self.embeddings_1(en1)\n",
        "        emb2 = self.embeddings_2(en2)\n",
        "        emb3 = self.embeddings_3(en3)\n",
        "        emb4 = self.embeddings_4(en4)\n",
        "\n",
        "        encoded1, encoded2, encoded3, encoded4, attn_weights = self.encoder(emb1,emb2,emb3,emb4)  # (B, n_patch, hidden)\n",
        "        x1 = self.reconstruct_1(encoded1) if en1 is not None else None\n",
        "        x2 = self.reconstruct_2(encoded2) if en2 is not None else None\n",
        "        x3 = self.reconstruct_3(encoded3) if en3 is not None else None\n",
        "        x4 = self.reconstruct_4(encoded4) if en4 is not None else None\n",
        "\n",
        "        x1 = x1 + en1  if en1 is not None else None\n",
        "        x2 = x2 + en2  if en2 is not None else None\n",
        "        x3 = x3 + en3  if en3 is not None else None\n",
        "        x4 = x4 + en4  if en4 is not None else None\n",
        "\n",
        "        return x1, x2, x3, x4, attn_weights"
      ],
      "metadata": {
        "id": "fXJismTtE2OR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class IntermediateSequential(nn.Sequential):\n",
        "    def __init__(self, *args, return_intermediate=False):\n",
        "        super().__init__(*args)\n",
        "        self.return_intermediate = return_intermediate\n",
        "\n",
        "    def forward(self, input): \n",
        "        if not self.return_intermediate:\n",
        "            return super().forward(input)\n",
        "\n",
        "        intermediate_outputs = {}\n",
        "        output = input\n",
        "        for name, module in self.named_children():\n",
        "            output = intermediate_outputs[name] = module(output)\n",
        "\n",
        "        return output, intermediate_outputs"
      ],
      "metadata": {
        "id": "4HzNrvp-GZQJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class FixedPositionalEncoding(nn.Module):\n",
        "    def __init__(self, embedding_dim, max_length=512):\n",
        "        super(FixedPositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_length, embedding_dim)\n",
        "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, embedding_dim, 2).float()\n",
        "            * (-torch.log(torch.tensor(10000.0)) / embedding_dim)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return x\n",
        "\n",
        "\n",
        "class LearnedPositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_position_embeddings, embedding_dim, seq_length):\n",
        "        super(LearnedPositionalEncoding, self).__init__()\n",
        "\n",
        "        self.position_embeddings = nn.Parameter(torch.zeros(1, 256, 512)) #8x\n",
        "\n",
        "    def forward(self, x, position_ids=None):\n",
        "\n",
        "        position_embeddings = self.position_embeddings\n",
        "        return x + position_embeddings"
      ],
      "metadata": {
        "id": "Go1kxgzBGgOs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "#from net.IntmdSequential import IntermediateSequential\n",
        "\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self, dim, heads=8, qkv_bias=False, qk_scale=None, dropout_rate=0.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.num_heads = heads\n",
        "        head_dim = dim // heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(dropout_rate)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = (\n",
        "            self.qkv(x)\n",
        "            .reshape(B, N, 3, self.num_heads, C // self.num_heads)\n",
        "            .permute(2, 0, 3, 1, 4)\n",
        "        )\n",
        "        q, k, v = (\n",
        "            qkv[0],\n",
        "            qkv[1],\n",
        "            qkv[2],\n",
        "        )  # make torchscript happy (cannot use tensor as tuple)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale \n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(x) + x\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(self.norm(x))\n",
        "\n",
        "\n",
        "class PreNormDrop(nn.Module):\n",
        "    def __init__(self, dim, dropout_rate, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.fn(self.norm(x)))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,  #512\n",
        "        depth,  #4\n",
        "        heads,  #8\n",
        "        mlp_dim,  #4096\n",
        "        dropout_rate=0.1,\n",
        "        attn_dropout_rate=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for _ in range(depth):\n",
        "            layers.extend(\n",
        "                [\n",
        "                    Residual(\n",
        "                        PreNormDrop(\n",
        "                            dim,\n",
        "                            dropout_rate,\n",
        "                            SelfAttention(dim, heads=heads, dropout_rate=attn_dropout_rate),\n",
        "                        )\n",
        "                    ),\n",
        "                    Residual(\n",
        "                        PreNorm(dim, FeedForward(dim, mlp_dim, dropout_rate))\n",
        "                    ),\n",
        "                ]\n",
        "            )\n",
        "            # dim = dim / 2\n",
        "        self.net = IntermediateSequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "rkdTTtF2GmV5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "#from net.IntmdSequential import IntermediateSequential\n",
        "\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self, dim, heads=8, qkv_bias=False, qk_scale=None, dropout_rate=0.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.num_heads = heads\n",
        "        head_dim = dim // heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(dropout_rate)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = (\n",
        "            self.qkv(x)\n",
        "            .reshape(B, N, 3, self.num_heads, C // self.num_heads)\n",
        "            .permute(2, 0, 3, 1, 4)\n",
        "        )\n",
        "        q, k, v = (\n",
        "            qkv[0],\n",
        "            qkv[1],\n",
        "            qkv[2],\n",
        "        )  # make torchscript happy (cannot use tensor as tuple)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale \n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(x) + x\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(self.norm(x))\n",
        "\n",
        "\n",
        "class PreNormDrop(nn.Module):\n",
        "    def __init__(self, dim, dropout_rate, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.fn(self.norm(x)))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,  #512\n",
        "        depth,  #4\n",
        "        heads,  #8\n",
        "        mlp_dim,  #4096\n",
        "        dropout_rate=0.1,\n",
        "        attn_dropout_rate=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for _ in range(depth):\n",
        "            layers.extend(\n",
        "                [\n",
        "                    Residual(\n",
        "                        PreNormDrop(\n",
        "                            dim,\n",
        "                            dropout_rate,\n",
        "                            SelfAttention(dim, heads=heads, dropout_rate=attn_dropout_rate),\n",
        "                        )\n",
        "                    ),\n",
        "                    Residual(\n",
        "                        PreNorm(dim, FeedForward(dim, mlp_dim, dropout_rate))\n",
        "                    ),\n",
        "                ]\n",
        "            )\n",
        "            # dim = dim / 2\n",
        "        self.net = IntermediateSequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "1ANcs0KeG06z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch\n",
        "import datetime\n",
        "import os\n",
        "import time\n",
        "import timeit\n",
        "import copy\n",
        "import numpy as np \n",
        "from torch.nn import ModuleList\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import LeakyReLU\n",
        "#from net.block import *\n",
        "#from net.block import _equalized_conv2d\n",
        "#from net.SGFMT import TransformerModel\n",
        "#from net.PositionalEncoding import FixedPositionalEncoding,LearnedPositionalEncoding\n",
        "#from net.CMSFFT import ChannelTransformer\n",
        "\n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\t\"\"\"\n",
        "\tMSG-Unet-GAN\n",
        "\t\"\"\"\n",
        "\tdef __init__(self,\n",
        "\t\timg_dim=256,\n",
        "\t\tpatch_dim=16,\n",
        "\t\tembedding_dim=512,\n",
        "\t\tnum_channels=3,\n",
        "\t\tnum_heads=8,\n",
        "\t\tnum_layers=4,\n",
        "\t\thidden_dim=256,\n",
        "\t\tdropout_rate=0.0,\n",
        "\t\tattn_dropout_rate=0.0,\n",
        "\t\tin_ch=3, \n",
        "\t\tout_ch=3,\n",
        "\t\tconv_patch_representation=True,\n",
        "\t\tpositional_encoding_type=\"learned\",\n",
        "\t\tuse_eql=True):\n",
        "\t\tsuper(Generator, self).__init__()\n",
        "\t\tassert embedding_dim % num_heads == 0\n",
        "\t\tassert img_dim % patch_dim == 0\n",
        "\n",
        "\t\tself.out_ch=out_ch\n",
        "\t\tself.in_ch=in_ch \n",
        "\t\tself.img_dim = img_dim   \n",
        "\t\tself.embedding_dim = embedding_dim  \n",
        "\t\tself.num_heads = num_heads \n",
        "\t\tself.patch_dim = patch_dim  \n",
        "\t\tself.num_channels = num_channels  \n",
        "\t\tself.dropout_rate = dropout_rate  \n",
        "\t\tself.attn_dropout_rate = attn_dropout_rate \n",
        "\t\tself.conv_patch_representation = conv_patch_representation \n",
        "\n",
        "\t\tself.num_patches = int((img_dim // patch_dim) ** 2)  \n",
        "\t\tself.seq_length = self.num_patches \n",
        "\t\tself.flatten_dim = 128 * num_channels \n",
        "\n",
        "\t\tself.linear_encoding = nn.Linear(self.flatten_dim, self.embedding_dim)\n",
        "\t\tif positional_encoding_type == \"learned\":\n",
        "\t\t\tself.position_encoding = LearnedPositionalEncoding(\n",
        "\t\t\t\tself.seq_length, self.embedding_dim, self.seq_length\n",
        "\t\t\t)\n",
        "\t\telif positional_encoding_type == \"fixed\":\n",
        "\t\t\tself.position_encoding = FixedPositionalEncoding(\n",
        "\t\t\t\tself.embedding_dim,\n",
        "\t\t\t)\n",
        "\n",
        "\t\tself.pe_dropout = nn.Dropout(p=self.dropout_rate)\n",
        "\n",
        "\t\tself.transformer = TransformerModel(\n",
        "\t\t\tembedding_dim, #512\n",
        "\t\t\tnum_layers, #4\n",
        "\t\t\tnum_heads,  #8\n",
        "\t\t\thidden_dim,  #4096\n",
        "\n",
        "\t\t\tself.dropout_rate,\n",
        "\t\t\tself.attn_dropout_rate,\n",
        "        )\n",
        "\n",
        "\t\t#layer Norm\n",
        "\t\tself.pre_head_ln = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "\t\tif self.conv_patch_representation:\n",
        "\n",
        "\t\t\tself.Conv_x = nn.Conv2d(\n",
        "\t\t\t\t256,\n",
        "\t\t\t\tself.embedding_dim,  #512\n",
        "\t\t\t\tkernel_size=3,\n",
        "\t\t\t\tstride=1,\n",
        "\t\t\t\tpadding=1\n",
        "\t\t    )\n",
        "\n",
        "\t\tself.bn = nn.BatchNorm2d(256)\n",
        "\t\tself.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\t\t#modulelist\n",
        "\t\tself.rgb_to_feature=ModuleList([from_rgb(32),from_rgb(64),from_rgb(128)])\n",
        "\t\tself.feature_to_rgb=ModuleList([to_rgb(32),to_rgb(64),to_rgb(128),to_rgb(256)])\n",
        "\n",
        "\t\tself.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\tself.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\tself.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\tself.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\tself.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\t\tself.Conv1=conv_block(self.in_ch, 16)\n",
        "\t\tself.Conv1_1 = conv_block(16, 32)\n",
        "\t\tself.Conv2 = conv_block(32, 32)\n",
        "\t\tself.Conv2_1 = conv_block(32, 64)\n",
        "\t\tself.Conv3 = conv_block(64,64)\n",
        "\t\tself.Conv3_1 = conv_block(64,128)\n",
        "\t\tself.Conv4 = conv_block(128,128)\n",
        "\t\tself.Conv4_1 = conv_block(128,256)\n",
        "\n",
        "\t\tself.Conv5 = conv_block(512,256)\n",
        "\n",
        "\t\t#self.Conv_x = conv_block(256,512)\n",
        "\t\tself.mtc = ChannelTransformer(channel_num=[32,64,128,256],\n",
        "\t\t\t\t\t\t\t\t\tpatchSize=[32, 16, 8, 4])\n",
        "\t\t\t\t\t\t\t\t\n",
        "\n",
        "\t\tself.Up5 = up_conv(256, 256)\n",
        "\t\tself.coatt5 = CCA(F_g=256, F_x=256)\n",
        "\t\tself.Up_conv5 = conv_block(512, 256)\n",
        "\t\tself.Up_conv5_1 = conv_block(256, 256)\n",
        "\n",
        "\t\tself.Up4 = up_conv(256, 128)\n",
        "\t\tself.coatt4 = CCA(F_g=128, F_x=128)\n",
        "\t\tself.Up_conv4 = conv_block(256, 128)\n",
        "\t\tself.Up_conv4_1 = conv_block(128, 128)\n",
        "\n",
        "\t\tself.Up3 = up_conv(128, 64)\n",
        "\t\tself.coatt3 = CCA(F_g=64, F_x=64)\n",
        "\t\tself.Up_conv3 = conv_block(128, 64)\n",
        "\t\tself.Up_conv3_1 = conv_block(64, 64)\n",
        "\n",
        "\t\tself.Up2 = up_conv(64, 32)\n",
        "\t\tself.coatt2 = CCA(F_g=32, F_x=32)\n",
        "\t\tself.Up_conv2 = conv_block(64, 32)\n",
        "\t\tself.Up_conv2_1 = conv_block(32, 32)\n",
        "\n",
        "\t\tself.Conv = nn.Conv2d(32, self.out_ch, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "\t\t# self.active = torch.nn.Sigmoid()\n",
        "\t\t# \n",
        "\tdef reshape_output(self,x):\n",
        "\t\tx = x.view(\n",
        "\t\t\tx.size(0),\n",
        "\t\t\tint(self.img_dim / self.patch_dim),\n",
        "\t\t\tint(self.img_dim / self.patch_dim),\n",
        "\t\t\tself.embedding_dim,\n",
        "\t\t\t)#B,16,16,512\n",
        "\t\tx = x.permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t#print(x.shape)\n",
        "\n",
        "\n",
        "\t\toutput=[]\n",
        "\n",
        "\t\tx_1=self.Maxpool(x)\n",
        "\t\tx_2=self.Maxpool(x_1)\n",
        "\t\tx_3=self.Maxpool(x_2)\n",
        "\n",
        "\n",
        "\t\te1 = self.Conv1(x)\n",
        "\t\t#print(e1.shape)\n",
        "\t\te1 = self.Conv1_1(e1)\n",
        "\t\te2 = self.Maxpool1(e1)\n",
        "\t\t#32*128*128\n",
        "\n",
        "\t\tx_1=self.rgb_to_feature[0](x_1)\n",
        "\t\t#e2=torch.cat((x_1,e2), dim=1)\n",
        "\t\te2=x_1+e2\n",
        "\t\te2 = self.Conv2(e2)\n",
        "\t\te2 = self.Conv2_1(e2)\n",
        "\t\te3 = self.Maxpool2(e2)\n",
        "\t\t#64*64*64\n",
        "\n",
        "\t\tx_2=self.rgb_to_feature[1](x_2)\n",
        "\t\t#e3=torch.cat((x_2,e3), dim=1)\n",
        "\t\te3=x_2+e3\n",
        "\t\te3 = self.Conv3(e3)\n",
        "\t\te3 = self.Conv3_1(e3)\n",
        "\t\te4 = self.Maxpool3(e3)\n",
        "\t\t#128*32*32\n",
        "\n",
        "\t\tx_3=self.rgb_to_feature[2](x_3)\n",
        "\t\t#e4=torch.cat((x_3,e4), dim=1)\n",
        "\t\te4=x_3+e4\n",
        "\t\te4 = self.Conv4(e4)\n",
        "\t\te4 = self.Conv4_1(e4)\n",
        "\t\te5 = self.Maxpool4(e4)\n",
        "\t\t#256*16*16\n",
        "\n",
        "\t\t#channel-wise transformer-based attention\n",
        "\t\te1,e2,e3,e4,att_weights = self.mtc(e1,e2,e3,e4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t#spatial-wise transformer-based attention\n",
        "\t\tresidual=e5\n",
        "\t\te5= self.bn(e5)\n",
        "\t\te5=self.relu(e5)\n",
        "\t\te5= self.Conv_x(e5) #out->512*16*16 shape->B,512,16,16\n",
        "\t\te5= e5.permute(0, 2, 3, 1).contiguous()  # B,512,16,16->B,16,16,512\n",
        "\t\te5= e5.view(e5.size(0), -1, self.embedding_dim) #B,16,16,512->B,16*16,512 线性映射层\n",
        "\t\te5= self.position_encoding(e5) \n",
        "\t\te5= self.pe_dropout(e5)\t \n",
        "\t\t# apply transformer\n",
        "\t\te5= self.transformer(e5)\n",
        "\t\te5= self.pre_head_ln(e5)\t\n",
        "\t\te5= self.reshape_output(e5)#out->512*16*16 shape->B,512,16,16\n",
        "\t\te5=self.Conv5(e5) #out->256,16,16 shape->B,256,16,16\n",
        "\t\t\n",
        "\t\te5=e5+residual\n",
        "\n",
        "\n",
        "\n",
        "\t\td5 = self.Up5(e5)\n",
        "\t\te4_att = self.coatt5(g=d5, x=e4)\n",
        "\t\td5 = torch.cat((e4_att, d5), dim=1)\n",
        "\t\td5 = self.Up_conv5(d5)\n",
        "\t\td5 = self.Up_conv5_1(d5)\n",
        "\t\t#256\n",
        "\t\tout3=self.feature_to_rgb[3](d5)\n",
        "\t\toutput.append(out3)#32*32orH/8,W/8\n",
        "\n",
        "\t\td4 = self.Up4(d5)\n",
        "\t\te3_att = self.coatt4(g=d4, x=e3)\n",
        "\t\td4 = torch.cat((e3_att, d4), dim=1)\n",
        "\t\td4 = self.Up_conv4(d4)\n",
        "\t\td4 = self.Up_conv4_1(d4)\n",
        "\t\t#128\n",
        "\t\tout2=self.feature_to_rgb[2](d4)\n",
        "\t\toutput.append(out2)#64*64orH/4,W/4\n",
        "\n",
        "\t\td3 = self.Up3(d4)\n",
        "\t\te2_att = self.coatt3(g=d3, x=e2)\n",
        "\t\td3 = torch.cat((e2_att, d3), dim=1)\n",
        "\t\td3 = self.Up_conv3(d3)\n",
        "\t\td3 = self.Up_conv3_1(d3)\n",
        "\t\t#64\n",
        "\t\tout1=self.feature_to_rgb[1](d3)\n",
        "\t\toutput.append(out1)#128#128orH/2,W/2\n",
        "\n",
        "\t\td2 = self.Up2(d3)\n",
        "\t\te1_att = self.coatt2(g=d2, x=e1)\n",
        "\t\td2 = torch.cat((e1_att, d2), dim=1)\n",
        "\t\td2 = self.Up_conv2(d2)\n",
        "\t\td2 = self.Up_conv2_1(d2)\n",
        "\t\t#32\n",
        "\t\tout0=self.feature_to_rgb[0](d2)\n",
        "\t\toutput.append(out0)#256*256\n",
        "\n",
        "\t\t#out = self.Conv(d2)\n",
        "\n",
        "\t\t#d1 = self.active(out)\n",
        "\t\t#output=np.array(output)\n",
        "\t\t\n",
        "\t\treturn output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3,use_eql=True):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.use_eql=use_eql\n",
        "        self.in_channels=in_channels\n",
        "\n",
        "\n",
        "        #modulelist\n",
        "        self.rgb_to_feature1=ModuleList([from_rgb(32),from_rgb(64),from_rgb(128)])\n",
        "        self.rgb_to_feature2=ModuleList([from_rgb(32),from_rgb(64),from_rgb(128)])\n",
        "\n",
        "\n",
        "        self.layer=_equalized_conv2d(self.in_channels*2, 64, (1, 1), bias=True)\n",
        "        # pixel_wise feature normalizer:\n",
        "        self.pixNorm = PixelwiseNorm()\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "\n",
        "        self.layer0=DisGeneralConvBlock(64,64,use_eql=self.use_eql)\n",
        "        #128*128*32\n",
        "        \n",
        "        self.layer1=DisGeneralConvBlock(128,128,use_eql=self.use_eql)\n",
        "        #64*64*64\n",
        "        \n",
        "        self.layer2=DisGeneralConvBlock(256,256,use_eql=self.use_eql)\n",
        "        #32*32*128\n",
        "        \n",
        "        self.layer3=DisGeneralConvBlock(512,512,use_eql=self.use_eql)\n",
        "        #16*16*256\n",
        "        \n",
        "        self.layer4=DisFinalBlock(512,use_eql=self.use_eql)\n",
        "        #8*8*512\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, img_A, inputs):\n",
        "    \t#inputs\n",
        "        # Concatenate image and condition image by channels to produce input\n",
        "        #img_input = torch.cat((img_A, img_B), 1)\n",
        "        #img_A_128= F.interpolate(img_A, size=[128, 128])\n",
        "        #img_A_64= F.interpolate(img_A, size=[64, 64])\n",
        "        #img_A_32= F.interpolate(img_A, size=[32, 32])\n",
        "\n",
        "\n",
        "        x=torch.cat((img_A[3], inputs[3]), 1)\n",
        "        y = self.pixNorm(self.lrelu(self.layer(x)))\n",
        "        \n",
        "        y=self.layer0(y)\n",
        "        #128*128*64\n",
        "        \n",
        "\n",
        "        x1=self.rgb_to_feature1[0](img_A[2])\n",
        "        x2=self.rgb_to_feature2[0](inputs[2])\n",
        "        x=torch.cat((x1,x2),1)\n",
        "        y=torch.cat((x,y),1)\n",
        "        y=self.layer1(y)\n",
        "        #64*64*128\n",
        "        \n",
        "\n",
        "        x1=self.rgb_to_feature1[1](img_A[1])\n",
        "        x2=self.rgb_to_feature2[1](inputs[1])\n",
        "        x=torch.cat((x1,x2),1)\n",
        "        y=torch.cat((x,y),1)\n",
        "        y=self.layer2(y)\n",
        "        #32*32*256\n",
        "        \n",
        "        x1=self.rgb_to_feature1[2](img_A[0])\n",
        "        x2=self.rgb_to_feature2[2](inputs[0])\n",
        "        x=torch.cat((x1,x2),1)\n",
        "        y=torch.cat((x,y),1)\n",
        "        y=self.layer3(y)\n",
        "        #16*16*512\n",
        "        \n",
        "        y=self.layer4(y)\n",
        "        #8*8*512\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "qR9_2mqVG7oU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch as th\n",
        "import datetime\n",
        "import os\n",
        "import time\n",
        "import timeit\n",
        "import copy\n",
        "import numpy as np \n",
        "from torch.nn import ModuleList\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import LeakyReLU\n",
        "\n",
        "\n",
        "class PixelwiseNorm(th.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PixelwiseNorm, self).__init__()\n",
        "\n",
        "    def forward(self, x, alpha=1e-8):\n",
        "        \"\"\"\n",
        "        forward pass of the module\n",
        "        :param x: input activations volume\n",
        "        :param alpha: small number for numerical stability\n",
        "        :return: y => pixel normalized activations\n",
        "        \"\"\"\n",
        "        y = x.pow(2.).mean(dim=1, keepdim=True).add(alpha).sqrt()  # [N1HW]\n",
        "        y = x / y  # normalize the input x volume\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "class MinibatchStdDev(th.nn.Module):\n",
        "    \"\"\"\n",
        "    Minibatch standard deviation layer for the discriminator\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        derived class constructor\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x, alpha=1e-8):\n",
        "        \"\"\"\n",
        "        forward pass of the layer\n",
        "        :param x: input activation volume\n",
        "        :param alpha: small number for numerical stability\n",
        "        :return: y => x appended with standard deviation constant map\n",
        "        \"\"\"\n",
        "        batch_size, _, height, width = x.shape\n",
        "\n",
        "        # [B x C x H x W] Subtract mean over batch.\n",
        "        y = x - x.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # [1 x C x H x W]  Calc standard deviation over batch\n",
        "        y = th.sqrt(y.pow(2.).mean(dim=0, keepdim=False) + alpha)\n",
        "\n",
        "        # [1]  Take average over feature_maps and pixels.\n",
        "        y = y.mean().view(1, 1, 1, 1)\n",
        "\n",
        "        # [B x 1 x H x W]  Replicate over group and pixels.\n",
        "        y = y.repeat(batch_size, 1, height, width)\n",
        "\n",
        "        # [B x C x H x W]  Append as new feature_map.\n",
        "        y = th.cat([x, y], 1)\n",
        "\n",
        "        # return the computed values:\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Equalized learning rate blocks:\n",
        "# extending Conv2D and Deconv2D layers for equalized learning rate logic\n",
        "# ==========================================================\n",
        "class _equalized_conv2d(th.nn.Module):\n",
        "    \"\"\" conv2d with the concept of equalized learning rate\n",
        "        Args:\n",
        "            :param c_in: input channels\n",
        "            :param c_out:  output channels\n",
        "            :param k_size: kernel size (h, w) should be a tuple or a single integer\n",
        "            :param stride: stride for conv\n",
        "            :param pad: padding\n",
        "            :param bias: whether to use bias or not\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out, k_size, stride=1, pad=0, bias=True):\n",
        "        \"\"\" constructor for the class \"\"\"\n",
        "        from torch.nn.modules.utils import _pair\n",
        "        from numpy import sqrt, prod\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # define the weight and bias if to be used\n",
        "        self.weight = th.nn.Parameter(th.nn.init.normal_(\n",
        "            th.empty(c_out, c_in, *_pair(k_size))\n",
        "        ))\n",
        "\n",
        "        self.use_bias = bias\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = th.nn.Parameter(th.FloatTensor(c_out).fill_(0))\n",
        "\n",
        "        fan_in = prod(_pair(k_size)) * c_in  # value of fan_in\n",
        "        self.scale = sqrt(2) / sqrt(fan_in)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the network\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        from torch.nn.functional import conv2d\n",
        "\n",
        "        return conv2d(input=x,\n",
        "                      weight=self.weight * self.scale,  # scale the weight on runtime\n",
        "                      bias=self.bias if self.use_bias else None,\n",
        "                      stride=self.stride,\n",
        "                      padding=self.pad)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return \", \".join(map(str, self.weight.shape))\n",
        "\n",
        "\n",
        "class _equalized_deconv2d(th.nn.Module):\n",
        "    \"\"\" Transpose convolution using the equalized learning rate\n",
        "        Args:\n",
        "            :param c_in: input channels\n",
        "            :param c_out: output channels\n",
        "            :param k_size: kernel size\n",
        "            :param stride: stride for convolution transpose\n",
        "            :param pad: padding\n",
        "            :param bias: whether to use bias or not\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out, k_size, stride=1, pad=0, bias=True):\n",
        "        \"\"\" constructor for the class \"\"\"\n",
        "        from torch.nn.modules.utils import _pair\n",
        "        from numpy import sqrt\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # define the weight and bias if to be used\n",
        "        self.weight = th.nn.Parameter(th.nn.init.normal_(\n",
        "            th.empty(c_in, c_out, *_pair(k_size))\n",
        "        ))\n",
        "\n",
        "        self.use_bias = bias\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = th.nn.Parameter(th.FloatTensor(c_out).fill_(0))\n",
        "\n",
        "        fan_in = c_in  # value of fan_in for deconv\n",
        "        self.scale = sqrt(2) / sqrt(fan_in)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the layer\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        from torch.nn.functional import conv_transpose2d\n",
        "\n",
        "        return conv_transpose2d(input=x,\n",
        "                                weight=self.weight * self.scale,  # scale the weight on runtime\n",
        "                                bias=self.bias if self.use_bias else None,\n",
        "                                stride=self.stride,\n",
        "                                padding=self.pad)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return \", \".join(map(str, self.weight.shape))\n",
        "\n",
        "\n",
        "\n",
        "#basic block of the encoding part of the genarater\n",
        "class conv_block(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolution Block \n",
        "    with two convolution layers\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, out_ch,use_eql=True):\n",
        "        super(conv_block, self).__init__()\n",
        "        \n",
        "        if use_eql:\n",
        "            self.conv_1=  _equalized_conv2d(in_ch, out_ch, (1, 1),\n",
        "                                            pad=0, bias=True)\n",
        "            self.conv_2 = _equalized_conv2d(out_ch, out_ch, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "            self.conv_3 = _equalized_conv2d(out_ch, out_ch, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "\n",
        "        else:\n",
        "            self.conv_1 = Conv2d(in_ch, out_ch, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "            self.conv_2 = Conv2d(out_ch, out_ch, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "\n",
        "        # pixel_wise feature normalizer:\n",
        "        self.pixNorm = PixelwiseNorm()\n",
        "\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the block\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        from torch.nn.functional import interpolate\n",
        "\n",
        "        #y = interpolate(x, scale_factor=2)\n",
        "        y=self.conv_1(self.lrelu(self.pixNorm(x)))\n",
        "        residual=y\n",
        "        y=self.conv_2(self.lrelu(self.pixNorm(y)))\n",
        "        y=self.conv_3(self.lrelu(self.pixNorm(y)))\n",
        "        y=y+residual\n",
        "\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#basic up convolution block of the encoding part of the genarater\n",
        "class up_conv(nn.Module):\n",
        "    \"\"\"\n",
        "    Up Convolution Block\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, out_ch,use_eql=True):\n",
        "        super(up_conv, self).__init__()\n",
        "        if use_eql:\n",
        "            self.conv_1=  _equalized_conv2d(in_ch, out_ch, (1, 1),\n",
        "                                            pad=0, bias=True)\n",
        "            self.conv_2 = _equalized_conv2d(out_ch, out_ch, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "            self.conv_3 = _equalized_conv2d(out_ch, out_ch, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "\n",
        "        else:\n",
        "            self.conv_1 = Conv2d(in_ch, out_ch, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "            self.conv_2 = Conv2d(out_ch, out_ch, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "\n",
        "        # pixel_wise feature normalizer:\n",
        "        self.pixNorm = PixelwiseNorm()\n",
        "\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the block\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        from torch.nn.functional import interpolate\n",
        "\n",
        "        x = interpolate(x, scale_factor=2, mode=\"bilinear\")\n",
        "        y=self.conv_1(self.lrelu(self.pixNorm(x)))\n",
        "        residual=y\n",
        "        y=self.conv_2(self.lrelu(self.pixNorm(y)))\n",
        "        y=self.conv_3(self.lrelu(self.pixNorm(y)))        \n",
        "        y=y+residual\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DisFinalBlock(th.nn.Module):\n",
        "    \"\"\" Final block for the Discriminator \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, use_eql=True):\n",
        "        \"\"\"\n",
        "        constructor of the class\n",
        "        :param in_channels: number of input channels\n",
        "        :param use_eql: whether to use equalized learning rate\n",
        "        \"\"\"\n",
        "        from torch.nn import LeakyReLU\n",
        "        from torch.nn import Conv2d\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # declare the required modules for forward pass\n",
        "        self.batch_discriminator = MinibatchStdDev()\n",
        "\n",
        "        if use_eql:\n",
        "            self.conv_1 = _equalized_conv2d(in_channels + 1, in_channels, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "            self.conv_2 = _equalized_conv2d(in_channels, in_channels, (4, 4),stride=2,pad=1,\n",
        "                                            bias=True)\n",
        "\n",
        "            # final layer emulates the fully connected layer\n",
        "            self.conv_3 = _equalized_conv2d(in_channels, 1, (1, 1), bias=True)\n",
        "\n",
        "        else:\n",
        "            # modules required:\n",
        "            self.conv_1 = Conv2d(in_channels + 1, in_channels, (3, 3), padding=1, bias=True)\n",
        "            self.conv_2 = Conv2d(in_channels, in_channels, (4, 4), bias=True)\n",
        "\n",
        "            # final conv layer emulates a fully connected layer\n",
        "            self.conv_3 = Conv2d(in_channels, 1, (1, 1), bias=True)\n",
        "\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the FinalBlock\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        # minibatch_std_dev layer\n",
        "        y = self.batch_discriminator(x)\n",
        "\n",
        "        # define the computations\n",
        "        y = self.lrelu(self.conv_1(y))\n",
        "        y = self.lrelu(self.conv_2(y))\n",
        "\n",
        "        # fully connected layer\n",
        "        y = self.conv_3(y)  # This layer has linear activation\n",
        "\n",
        "        # flatten the output raw discriminator scores\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "class DisGeneralConvBlock(th.nn.Module):\n",
        "    \"\"\" General block in the discriminator  \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, use_eql=True):\n",
        "        \"\"\"\n",
        "        constructor of the class\n",
        "        :param in_channels: number of input channels\n",
        "        :param out_channels: number of output channels\n",
        "        :param use_eql: whether to use equalized learning rate\n",
        "        \"\"\"\n",
        "        from torch.nn import AvgPool2d, LeakyReLU\n",
        "        from torch.nn import Conv2d\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        if use_eql:\n",
        "            self.conv_1 = _equalized_conv2d(in_channels, in_channels, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "            self.conv_2 = _equalized_conv2d(in_channels, out_channels, (3, 3),\n",
        "                                            pad=1, bias=True)\n",
        "        else:\n",
        "            # convolutional modules\n",
        "            self.conv_1 = Conv2d(in_channels, in_channels, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "            self.conv_2 = Conv2d(in_channels, out_channels, (3, 3),\n",
        "                                 padding=1, bias=True)\n",
        "\n",
        "        self.downSampler = AvgPool2d(2)  # downsampler\n",
        "\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the module\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        # define the computations\n",
        "        y = self.lrelu(self.conv_1(x))\n",
        "        y = self.lrelu(self.conv_2(y))\n",
        "        y = self.downSampler(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "class from_rgb(nn.Module):\n",
        "    \"\"\"\n",
        "    The RGB image is transformed into a multi-channel feature map to be concatenated with \n",
        "    the feature map with the same number of channels in the network\n",
        "    把RGB图转换为多通道特征图，以便与网络中相同通道数的特征图拼接\n",
        "    \"\"\"\n",
        "    def __init__(self, outchannels, use_eql=True):\n",
        "        super(from_rgb, self).__init__()\n",
        "        if use_eql:\n",
        "            self.conv_1 = _equalized_conv2d(3, outchannels, (1, 1), bias=True)\n",
        "        else:\n",
        "            self.conv_1 = nn.Conv2d(3, outchannels, (1, 1),bias=True)\n",
        "        # pixel_wise feature normalizer:\n",
        "        self.pixNorm = PixelwiseNorm()\n",
        "\n",
        "        # leaky_relu:\n",
        "        self.lrelu = LeakyReLU(0.2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the block\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "        y = self.pixNorm(self.lrelu(self.conv_1(x)))\n",
        "        return y\n",
        "\n",
        "class to_rgb(nn.Module):\n",
        "    \"\"\"\n",
        "    The multi-channel feature map is converted into RGB image for input to the discriminator\n",
        "    \"\"\"\n",
        "    def __init__(self, inchannels, use_eql=True):\n",
        "        super(to_rgb, self).__init__()\n",
        "        if use_eql:\n",
        "            self.conv_1 = _equalized_conv2d(inchannels, 3, (1, 1), bias=True)\n",
        "        else:\n",
        "            self.conv_1 = nn.Conv2d(inchannels, 3, (1, 1),bias=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward pass of the block\n",
        "        :param x: input\n",
        "        :return: y => output\n",
        "        \"\"\"\n",
        "\n",
        "        y = self.conv_1(x)\n",
        "\n",
        "        return y\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "\n",
        "\n",
        "class CCA(nn.Module):\n",
        "    \"\"\"\n",
        "    CCA Block\n",
        "    \"\"\"\n",
        "    def __init__(self, F_g, F_x):\n",
        "        super().__init__()\n",
        "        self.mlp_x = nn.Sequential(\n",
        "            Flatten(),\n",
        "            nn.Linear(F_x, F_x))\n",
        "        self.mlp_g = nn.Sequential(\n",
        "            Flatten(),\n",
        "            nn.Linear(F_g, F_x))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        # channel-wise attention\n",
        "        avg_pool_x = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
        "        channel_att_x = self.mlp_x(avg_pool_x)\n",
        "        avg_pool_g = F.avg_pool2d( g, (g.size(2), g.size(3)), stride=(g.size(2), g.size(3)))\n",
        "        channel_att_g = self.mlp_g(avg_pool_g)\n",
        "        channel_att_sum = (channel_att_x + channel_att_g)/2.0\n",
        "        scale = th.sigmoid(channel_att_sum).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
        "        x_after_channel = x * scale\n",
        "        out = self.relu(x_after_channel)\n",
        "        return out"
      ],
      "metadata": {
        "id": "NHu2M53DHFSm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "#from skimage.measure.simple_metrics import compare_psnr\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "def weights_init_kaiming(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
        "    elif classname.find('Linear') != -1:\n",
        "        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        # nn.init.uniform(m.weight.data, 1.0, 0.02)\n",
        "        m.weight.data.normal_(mean=0, std=math.sqrt(2./9./64.)).clamp_(-0.025,0.025)\n",
        "        nn.init.constant(m.bias.data, 0.0)\n",
        "\n",
        "class VGG19_PercepLoss(nn.Module):\n",
        "    \"\"\" Calculates perceptual loss in vgg19 space\n",
        "    \"\"\"\n",
        "    def __init__(self, _pretrained_=True):\n",
        "        super(VGG19_PercepLoss, self).__init__()\n",
        "        self.vgg = models.vgg19(pretrained=_pretrained_).features\n",
        "        for param in self.vgg.parameters():\n",
        "            param.requires_grad_(False)\n",
        "\n",
        "    def get_features(self, image, layers=None):\n",
        "        if layers is None: \n",
        "            layers = {'30': 'conv5_2'} # may add other layers\n",
        "        features = {}\n",
        "        x = image\n",
        "        for name, layer in self.vgg._modules.items():\n",
        "            x = layer(x)\n",
        "            if name in layers:\n",
        "                features[layers[name]] = x\n",
        "        return features\n",
        "\n",
        "    def forward(self, pred, true, layer='conv5_2'):\n",
        "        true_f = self.get_features(true)\n",
        "        pred_f = self.get_features(pred)\n",
        "        return torch.mean((true_f[layer]-pred_f[layer])**2)\n",
        "\n",
        "\n",
        "def batch_PSNR(img, imclean, data_range):\n",
        "    Img = img.data.cpu().numpy().astype(np.float32)\n",
        "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
        "    PSNR = 0\n",
        "    for i in range(Img.shape[0]):\n",
        "        PSNR += compare_psnr(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
        "    return (PSNR/Img.shape[0])\n",
        "\n",
        "def data_augmentation(image, mode):\n",
        "    out = np.transpose(image, (1,2,0))\n",
        "    #out = image\n",
        "    if mode == 0:\n",
        "        # original\n",
        "        out = out\n",
        "    elif mode == 1:\n",
        "        # flip up and down\n",
        "        out = np.flipud(out)\n",
        "    elif mode == 2:\n",
        "        # rotate counterwise 90 degree\n",
        "        out = np.rot90(out)\n",
        "    elif mode == 3:\n",
        "        # rotate 90 degree and flip up and down\n",
        "        out = np.rot90(out)\n",
        "        out = np.flipud(out)\n",
        "    elif mode == 4:\n",
        "        # rotate 180 degree\n",
        "        out = np.rot90(out, k=2)\n",
        "    elif mode == 5:\n",
        "        # rotate 180 degree and flip\n",
        "        out = np.rot90(out, k=2)\n",
        "        out = np.flipud(out)\n",
        "    elif mode == 6:\n",
        "        # rotate 270 degree\n",
        "        out = np.rot90(out, k=3)\n",
        "    elif mode == 7:\n",
        "        # rotate 270 degree and flip\n",
        "        out = np.rot90(out, k=3)\n",
        "        out = np.flipud(out)\n",
        "    return np.transpose(out, (2,0,1))\n",
        "    #return out"
      ],
      "metadata": {
        "id": "VQoWmzsfHVfd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from math import exp\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
        "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
        "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1*mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01**2\n",
        "    C2 = 0.03**2\n",
        "\n",
        "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size = 11, size_average = True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "            \n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "            \n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
        "\n",
        "def ssim(img1, img2, window_size = 11, size_average = True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "    \n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "    \n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)"
      ],
      "metadata": {
        "id": "rn9wy3xHHcB5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from math import exp\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
        "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
        "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1*mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01**2\n",
        "    C2 = 0.03**2\n",
        "\n",
        "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size = 11, size_average = True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "            \n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "            \n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
        "\n",
        "def ssim(img1, img2, window_size = 11, size_average = True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "    \n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "    \n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)"
      ],
      "metadata": {
        "id": "Qse-tOL4IAAQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import itertools\n",
        "\"\"\"\n",
        "Qnt: Quantization Methods. this collection of methods, compute the quantization tables  for RGB, and LAB color space. \n",
        "These methods are organized in a way that each bin is recognized by its central value.\n",
        "ES: RGB 0-255\n",
        "    2 levels of quantization for each channel\n",
        "    0-127:128-255. these two intervals are represented as 63.5 and 191.5 in the table.\n",
        "    then, only for RGB, the values are normalized in 0-1 range\n",
        "    \n",
        "    For L and AB the methods provide in output the 2D and 1D quantization tables. The values are not normalized.\n",
        "\"\"\"\n",
        "def quantRGB(bins,vmax=255,vmin=0):\n",
        "    a = torch.linspace(vmin+((vmax-vmin)/(bins*2)), vmax-((vmax-vmin)/(bins*2)), bins)\n",
        "    mat=torch.cartesian_prod(a,a,a)/vmax\n",
        "    return mat.view(1,bins**3,3,1,1)\n",
        "\n",
        "def quantL(bins,vmax,vmin):\n",
        "    a = torch.linspace(vmin+((vmax-vmin)/(bins*2)), vmax-((vmax-vmin)/(bins*2)), bins)\n",
        "    mat = a\n",
        "    return mat.view(1,bins,1,1)\n",
        "\n",
        "\n",
        "def quantAB(bins, vmax,vmin):\n",
        "    a = torch.linspace(vmin+((vmax-vmin)/(bins*2)), vmax-((vmax-vmin)/(bins*2)), bins)\n",
        "    mat=torch.cartesian_prod(a,a)\n",
        "    return mat.view(1,bins**2,2,1,1)"
      ],
      "metadata": {
        "id": "m4i0b--EIOZo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "id": "FcPex4ATIx8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d938177-e140-4b54-b539-2dcd3385ff5d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib==3.1.3 in /usr/local/lib/python3.7/dist-packages (3.1.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.1.3) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#from utility import ptcolor as ptcolor\n",
        "\"\"\"\n",
        "Relu_Softmax_LAB: This collections of methods compute the softmax (on channel L or AB) using the principles:\n",
        "high value for taller bins and very low values for shorter bins ( almost 0 everywhere).\n",
        "\"\"\"\n",
        "\n",
        "def softquant(x, vmin, vmax, bins):\n",
        "    slope = (bins - 1) / (vmax - vmin)\n",
        "    a = torch.linspace(vmin, vmax, bins, device=x.device)\n",
        "    diff = (x.unsqueeze(-1) - a).abs()\n",
        "    return torch.nn.functional.relu(1 - diff * slope) #high value for taller bins, everywhere else almost 0\n",
        "\n",
        "def softhist_L(x, vmin, vmax, bins):\n",
        "    x = torch.clamp(x, vmin, vmax)\n",
        "    q = softquant(x, vmin, vmax, bins)\n",
        "    return q.view(x.size(0), -1, bins).mean(1)\n",
        "\n",
        "\n",
        "def softhist_AB(lab, vmax, bins):\n",
        "    a = torch.clamp(lab[:, 1, :, :], -vmax, vmax)\n",
        "    b = torch.clamp(lab[:, 2, :, :], -vmax, vmax)\n",
        "    qa = softquant(a, -vmax, vmax, bins).to(device=lab.device)\n",
        "    qb = softquant(b, -vmax, vmax, bins).to(lab.device)\n",
        "    return torch.einsum(\"bijc,bijd->bcd\", qa, qb).to(lab.device) / (a.size(1) * a.size(2))\n",
        "\n",
        "#ptcolor.py\n",
        "def _t(data):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    return torch.tensor(data, requires_grad=False, dtype=torch.float32, device=device)\n",
        "\n",
        "\n",
        "# Helper for color matrix multiplication\n",
        "def _mul(coeffs, image):\n",
        "    coeffs = coeffs.to(image.device).view(3, 3, 1, 1)\n",
        "    return torch.nn.functional.conv2d(image, coeffs)\n",
        "\n",
        "\n",
        "_RGB_TO_XYZ = {\n",
        "    \"srgb\": _t([[0.4124564, 0.3575761, 0.1804375],\n",
        "                [0.2126729, 0.7151522, 0.0721750],\n",
        "                [0.0193339, 0.1191920, 0.9503041]]),\n",
        "\n",
        "    \"prophoto\": _t([[0.7976749, 0.1351917, 0.0313534],\n",
        "                    [0.2880402, 0.7118741, 0.0000857],\n",
        "                    [0.0000000, 0.0000000, 0.8252100]])\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "_XYZ_TO_RGB = {\n",
        "    \"srgb\": _t([[3.2404542, -1.5371385, -0.4985314],\n",
        "                   [-0.9692660, 1.8760108, 0.0415560],\n",
        "                   [0.0556434, -0.2040259, 1.0572252]]),\n",
        "\n",
        "    \"prophoto\": _t([[ 1.3459433, -0.2556075, -0.0511118],\n",
        "                    [-0.5445989,  1.5081673,  0.0205351],\n",
        "                    [0.0000000,  0.0000000,  1.2118128]])\n",
        "    }\n",
        "\n",
        "\n",
        "WHITE_POINTS = {item[0]: _t(item[1:]).view(1, 3, 1, 1) for item in [\n",
        "    (\"a\", 1.0985, 1.0000, 0.3558),\n",
        "    (\"b\", 0.9807, 1.0000, 1.1822),\n",
        "    (\"e\", 1.0000, 1.0000, 1.0000),\n",
        "    (\"d50\", 0.9642, 1.0000, 0.8251),\n",
        "    (\"d55\", 0.9568, 1.0000, 0.9214),\n",
        "    (\"d65\", 0.9504, 1.0000, 1.0888),\n",
        "    (\"icc\", 0.9642, 1.0000, 0.8249)\n",
        "]}\n",
        "\n",
        "\n",
        "_EPSILON = 0.008856\n",
        "_KAPPA = 903.3\n",
        "_XYZ_TO_LAB = _t([[0.0, 116.0, 0.], [500.0, -500.0, 0.], [0.0, 200.0, -200.0]])\n",
        "_LAB_TO_XYZ = _t([[1.0 / 116.0, 1.0 / 500.0, 0], [1.0 / 116.0, 0, 0], [1.0 / 116.0, 0, -1.0 / 200.0]])\n",
        "_LAB_OFF = _t([16.0, 0.0, 0.0]).view(1, 3, 1, 1)\n",
        "\n",
        "\n",
        "def apply_gamma(rgb, gamma=\"srgb\"):\n",
        "    \"\"\"Linear to gamma rgb.\n",
        "    Assume that rgb values are in the [0, 1] range (but values outside are tolerated).\n",
        "    gamma can be \"srgb\", a real-valued exponent, or None.\n",
        "    >>> apply_gamma(torch.tensor([0.5, 0.4, 0.1]).view([1, 3, 1, 1]), 0.5).view(-1)\n",
        "    tensor([0.2500, 0.1600, 0.0100])\n",
        "    \"\"\"\n",
        "    if gamma == \"srgb\":\n",
        "        T = 0.0031308\n",
        "        rgb1 = torch.max(rgb, rgb.new_tensor(T))\n",
        "        return torch.where(rgb < T, 12.92 * rgb, (1.055 * torch.pow(torch.abs(rgb1), 1 / 2.4) - 0.055))\n",
        "    elif gamma is None:\n",
        "        return rgb\n",
        "    else:\n",
        "        return torch.pow(torch.max(rgb, rgb.new_tensor(0.0)), 1.0 / gamma)\n",
        "\n",
        "\n",
        "\n",
        "def remove_gamma(rgb, gamma=\"srgb\"):\n",
        "    \"\"\"Gamma to linear rgb.\n",
        "    Assume that rgb values are in the [0, 1] range (but values outside are tolerated).\n",
        "    gamma can be \"srgb\", a real-valued exponent, or None.\n",
        "    >>> remove_gamma(apply_gamma(torch.tensor([0.001, 0.3, 0.4])))\n",
        "    tensor([0.0010,  0.3000,  0.4000])\n",
        "    >>> remove_gamma(torch.tensor([0.5, 0.4, 0.1]).view([1, 3, 1, 1]), 2.0).view(-1)\n",
        "    tensor([0.2500, 0.1600, 0.0100])\n",
        "    \"\"\"\n",
        "    if gamma == \"srgb\":\n",
        "        T = 0.04045\n",
        "        rgb1 = torch.max(rgb, rgb.new_tensor(T))\n",
        "        return torch.where(rgb < T, rgb / 12.92, torch.pow(torch.abs(rgb1 + 0.055) / 1.055, 2.4))\n",
        "    elif gamma is None:\n",
        "        return rgb\n",
        "    else:\n",
        "        res = torch.pow(torch.max(rgb, rgb.new_tensor(0.0)), gamma) + \\\n",
        "              torch.min(rgb, rgb.new_tensor(0.0)) # very important to avoid vanishing gradients\n",
        "        return res\n",
        "\n",
        "\n",
        "def rgb2xyz(rgb, gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to XYZ conversion.\n",
        "    rgb:  Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> rgb2xyz(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> rgb2xyz(torch.tensor([0., 0.75, 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.1868,  0.3737,  0.0623])\n",
        "    >>> rgb2xyz(torch.tensor([0.4, 0.8, 0.2]).view(1, 3, 1, 1), gamma_correction=None).view(-1)\n",
        "    tensor([0.4871,  0.6716,  0.2931])\n",
        "    >>> rgb2xyz(torch.ones(2, 3, 4, 5)).size()\n",
        "    torch.Size([2, 3, 4, 5])\n",
        "    >>> xyz2rgb(torch.tensor([-1, 2., 0.]).view(1, 3, 1, 1), clip_rgb=True).view(-1)\n",
        "    tensor([0.0000,  1.0000,  0.0000])\n",
        "    >>> rgb2xyz(torch.tensor([0.4, 0.8, 0.2]).view(1, 3, 1, 1), gamma_correction=None, space='prophoto').view(-1)\n",
        "    tensor([0.4335,  0.6847,  0.1650])\n",
        "    \"\"\"\n",
        "    if clip_rgb:\n",
        "        rgb = torch.clamp(rgb, 0, 1)\n",
        "    rgb = remove_gamma(rgb, gamma_correction)\n",
        "    return _mul(_RGB_TO_XYZ[space], rgb)\n",
        "\n",
        "\n",
        "def xyz2rgb(xyz, gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"XYZ to sRGB conversion.\n",
        "    rgb:  Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> xyz2rgb(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> xyz2rgb(torch.tensor([0.04, 0.02, 0.05]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.3014,  0.0107,  0.2503])\n",
        "    >>> xyz2rgb(torch.ones(2, 3, 4, 5)).size()\n",
        "    torch.Size([2, 3, 4, 5])\n",
        "    >>> xyz2rgb(torch.tensor([-1, 2., 0.]).view(1, 3, 1, 1), clip_rgb=True).view(-1)\n",
        "    tensor([0.0000,  1.0000,  0.0000])\n",
        "    \"\"\"\n",
        "    rgb = _mul(_XYZ_TO_RGB[space], xyz)\n",
        "    if clip_rgb:\n",
        "        rgb = torch.clamp(rgb, 0, 1)\n",
        "    rgb = apply_gamma(rgb, gamma_correction)\n",
        "    return rgb\n",
        "\n",
        "\n",
        "def _lab_f(x):\n",
        "    x1 = torch.max(x, x.new_tensor(_EPSILON))\n",
        "    return torch.where(x > _EPSILON, torch.pow(x1, 1.0 / 3), (_KAPPA * x + 16.0) / 116.0)\n",
        "\n",
        "\n",
        "def xyz2lab(xyz, white_point=\"d65\"):\n",
        "    \"\"\"XYZ to Lab conversion.\n",
        "    xyz: Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> xyz2lab(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> xyz2lab(torch.tensor([0.4, 0.2, 0.1]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([51.8372,  82.3018,  26.7245])\n",
        "    >>> xyz2lab(torch.tensor([1., 1., 1.]).view(1, 3, 1, 1), white_point=\"e\").view(-1)\n",
        "    tensor([100., 0., 0.])\n",
        "    \"\"\"\n",
        "    xyz = xyz / WHITE_POINTS[white_point].to(xyz.device)\n",
        "    f_xyz = _lab_f(xyz)\n",
        "    return _mul(_XYZ_TO_LAB, f_xyz) - _LAB_OFF.to(xyz.device)\n",
        "\n",
        "\n",
        "def _inv_lab_f(x):\n",
        "    x3 = torch.max(x, x.new_tensor(_EPSILON)) ** 3\n",
        "    return torch.where(x3 > _EPSILON, x3, (116.0 * x - 16.0) / _KAPPA)\n",
        "\n",
        "\n",
        "def lab2xyz(lab, white_point=\"d65\"):\n",
        "    \"\"\"lab to XYZ conversion.\n",
        "    lab: Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> lab2xyz(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> lab2xyz(torch.tensor([100., 0., 0.]).view(1, 3, 1, 1), white_point=\"e\").view(-1)\n",
        "    tensor([1.,  1.,  1.])\n",
        "    >>> lab2xyz(torch.tensor([50., 25., -30.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.2254,  0.1842,  0.4046])\n",
        "    \"\"\"\n",
        "    f_xyz = _mul(_LAB_TO_XYZ, lab + _LAB_OFF.to(lab.device))\n",
        "    xyz = _inv_lab_f(f_xyz)\n",
        "    return xyz * WHITE_POINTS[white_point].to(lab.device)\n",
        "\n",
        "\n",
        "def rgb2lab(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to Lab conversion.\"\"\"\n",
        "    lab = xyz2lab(rgb2xyz(rgb, gamma_correction, clip_rgb, space), white_point)\n",
        "    return lab\n",
        "\n",
        "\n",
        "def lab2rgb(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"Lab to sRGB conversion.\"\"\"\n",
        "    return xyz2rgb(lab2xyz(rgb, white_point), gamma_correction, clip_rgb, space)\n",
        "\n",
        "def lab2lch(lab):\n",
        "    \"\"\"Lab to LCH conversion.\"\"\"\n",
        "    l = lab[:, 0, :, :]\n",
        "    c = torch.norm(lab[:, 1:, :, :], 2, 1)\n",
        "    h = torch.atan2(lab[:, 2, :, :], lab[:, 1, :, :])\n",
        "    h = h * (180 / 3.141592653589793)\n",
        "    h = torch.where(h >= 0, h, 360 + h)\n",
        "    return torch.stack([l, c, h], 1)\n",
        "\n",
        "\n",
        "def rgb2lch(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to LCH conversion.\"\"\"\n",
        "    lab = rgb2lab(rgb, white_point, gamma_correction, clip_rgb, space)\n",
        "    return lab2lch(lab)\n",
        "\n",
        "def squared_deltaE(lab1, lab2):\n",
        "    \"\"\"Squared Delta E (CIE 1976).\n",
        "    lab1: Bx3xHxW\n",
        "    lab2: Bx3xHxW\n",
        "    return: Bx1xHxW\n",
        "    \"\"\"\n",
        "    return torch.sum((lab1 - lab2) ** 2, 1, keepdim=True)\n",
        "\n",
        "\n",
        "def deltaE(lab1, lab2):\n",
        "    \"\"\"Delta E (CIE 1976).\n",
        "    lab1: Bx3xHxW\n",
        "    lab2: Bx3xHxW\n",
        "    return: Bx1xHxW\n",
        "    >>> lab1 = torch.tensor([100., 75., 50.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([50., 50., 100.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE(lab1, lab2).item()\n",
        "    75.0\n",
        "    \"\"\"\n",
        "    return torch.norm(lab1 - lab2, 2, 1, keepdim=True)\n",
        "\n",
        "\n",
        "def squared_deltaE94(lab1, lab2):\n",
        "    \"\"\"Squared Delta E (CIE 1994).\n",
        "    Default parameters for the 'Graphic Art' version.\n",
        "    lab1: Bx3xHxW   (reference color)\n",
        "    lab2: Bx3xHxW   (other color)\n",
        "    return: Bx1xHxW\n",
        "    \"\"\"\n",
        "    diff_2 = (lab1 - lab2) ** 2\n",
        "    dl_2 = diff_2[:, 0:1, :, :]\n",
        "    c1 = torch.norm(lab1[:, 1:3, :, :], 2, 1, keepdim=True)\n",
        "    c2 = torch.norm(lab2[:, 1:3, :, :], 2, 1, keepdim=True)\n",
        "    dc_2 = (c1 - c2) ** 2\n",
        "    dab_2 = torch.sum(diff_2[:, 1:3, :, :], 1, keepdim=True)\n",
        "    dh_2 = torch.abs(dab_2 - dc_2)\n",
        "    de_2 = (dl_2 +\n",
        "            dc_2 / ((1 + 0.045 * c1) ** 2) +\n",
        "            dh_2 / ((1 + 0.015 * c1) ** 2))\n",
        "    return de_2\n",
        "\n",
        "\n",
        "def deltaE94(lab1, lab2):\n",
        "    \"\"\"Delta E (CIE 1994).\n",
        "    Default parameters for the 'Graphic Art' version.\n",
        "    lab1: Bx3xHxW   (reference color)\n",
        "    lab2: Bx3xHxW   (other color)\n",
        "    return: Bx1xHxW\n",
        "    >>> lab1 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([80., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE94(lab1, lab2).item()\n",
        "    20.0\n",
        "    >>> lab1 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([100., 20., 0.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE94(lab1, lab2).item()\n",
        "    20.0\n",
        "    >>> lab1 = torch.tensor([100., 0., 10.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> round(deltaE94(lab1, lab2).item(), 4)\n",
        "    6.8966\n",
        "    >>> lab1 = torch.tensor([100., 75., 50.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([50., 50., 100.]).view(1, 3, 1, 1)\n",
        "    >>> round(deltaE94(lab1, lab2).item(), 4)\n",
        "    54.7575\n",
        "    \"\"\"\n",
        "    # The ReLU prevents from NaNs in gradient computation\n",
        "    sq = torch.nn.functional.relu(squared_deltaE94(lab1, lab2))\n",
        "    return torch.sqrt(sq)\n",
        "\n",
        "\n",
        "def _check_conversion(**opts):\n",
        "    \"\"\"Verify the conversions on the RGB cube.\n",
        "    >>> _check_conversion(white_point='d65', gamma_correction='srgb', clip_rgb=False, space='srgb')\n",
        "    True\n",
        "    >>> _check_conversion(white_point='d50', gamma_correction=1.8, clip_rgb=False, space='prophoto')\n",
        "    True\n",
        "    \"\"\"\n",
        "    for r in range(0, 256, 15):\n",
        "        for g in range(0, 256, 15):\n",
        "            for b in range(0, 256, 15):\n",
        "                rgb = torch.tensor([r / 255.0, g / 255.0, b / 255.0]).view(1, 3, 1, 1)\n",
        "                lab = rgb2lab(rgb, **opts)\n",
        "                rgb2 = lab2rgb(lab, **opts)\n",
        "                de = deltaE(rgb, rgb2).item()\n",
        "                if de > 2e-4:\n",
        "                    print(\"Conversion failed for RGB:\", r, g, b, \" deltaE\", de)\n",
        "                    return False\n",
        "    return True\n",
        "#ptcolor.end\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    im = torch.randn([1,3,64,64])\n",
        "    lab = rgb2lab(im)\n",
        "    for c in (0, 1, 2):\n",
        "        print(lab[:, c, :, :].min(), lab[:, c, :, :].max())\n",
        "    hist_l = softhist_L(lab[:, 0, :, :], 0, 100, 50)\n",
        "    print(hist_l.shape)\n",
        "    hist_ab = softhist_AB(lab, 80, 20)\n",
        "    plt.plot(hist_l[0].numpy())\n",
        "    plt.figure()\n",
        "    plt.imshow(hist_ab[0].numpy())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YkyMAQpYIb0A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "4cbc93c1-2b67-470c-8617-097e7e2fd147"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-155.1011) tensor(267.2605)\n",
            "tensor(-340.2436) tensor(448.6260)\n",
            "tensor(-346.8746) tensor(393.1568)\n",
            "torch.Size([1, 50])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import data\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\"\"\"\n",
        "Five K Dataset: \n",
        "    constructor params: \n",
        "        -list_file: path of a file with the list of images\n",
        "        -raw_dir: path of the directory which contains raw images\n",
        "        -expert_dir: path of the directory which contains expert images\n",
        "        -training: if True, horizontal flip is applied\n",
        "        -size: if is not None, resize is applied\n",
        "        -filenames, if is true, __getitem__ returns also the name of the image taken  \n",
        "\"\"\"\n",
        "\n",
        "class FiveKDataset(data.Dataset):\n",
        "    def __init__(self, list_file, raw_dir, expert_dir, training, size=None, filenames=False):\n",
        "        join = os.path.join\n",
        "        self.file_list = []\n",
        "        with open(list_file) as f:\n",
        "            for line in f:\n",
        "                name = line.strip()\n",
        "                if name:\n",
        "                    p = (join(raw_dir, name), join(expert_dir, name), name)\n",
        "                    self.file_list.append(p)\n",
        "        self.filenames = filenames\n",
        "        transformation=[]\n",
        "        if size is not None:\n",
        "          transformation.append(transforms.Resize((size,size)))\n",
        "        if training:\n",
        "          transformation.append(transforms.RandomHorizontalFlip(0.5))\n",
        "        transformation.append(transforms.ToTensor())\n",
        "        self.transform=transforms.Compose(transformation)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "   # def __getitem__(self, index):\n",
        "    #    raw = Image.open(self.file_list[index][0])\n",
        "     #   expert =  Image.open(self.file_list[index][1])\n",
        "      #  raw_exp = self.transform(torch.stack([raw, expert]))\n",
        "       # if self.filenames:\n",
        "        #    return raw_exp[0],raw_exp[1], self.file_list[index][2]\n",
        "        #else:\n",
        "         #   return raw_exp[0],raw_exp[1]\n",
        "\n",
        "\n",
        "def _test():\n",
        "    train_list = \"/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test1.txt\"\n",
        "    raw_dir = \"/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test1\"\n",
        "    expert_dir = \"/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test1\"\n",
        "    dataset = FiveKDataset(train_list, raw_dir, expert_dir, True, None)\n",
        "    loader = torch.utils.data.DataLoader(dataset, 10, shuffle=True,num_workers=16)\n",
        "    for raw, expert in loader:\n",
        "        print(raw.size(), expert.size())\n",
        "\n",
        "\n",
        "\n",
        "def _test():\n",
        "    train_list = \"/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/train1.txt\"\n",
        "    raw_dir = \"/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/train1\"\n",
        "    expert_dir = \"/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/train1\"\n",
        "    dataset = FiveKDataset(train_list, raw_dir, expert_dir, True, None)\n",
        "    loader = torch.utils.data.DataLoader(dataset, 10, shuffle=True)\n",
        "    #for raw, expert in loader:\n",
        "     #   print(raw.size(), expert.size())\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    _test()"
      ],
      "metadata": {
        "id": "8AkK6axoKQuz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtcLcA13OXFk",
        "outputId": "a4b78886-7514-4c77-c9d1-be6678b445f9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "if __name__ != \"__main__\":\n",
        "    matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def make_plots(data, height, width, dpi=100.0, rgbonly=False):\n",
        "    n = data.shape[1]\n",
        "    x = np.linspace(0, 1, n)\n",
        "    fig = plt.figure(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
        "    plt.grid()\n",
        "    styles = [\"r-\", \"g-\", \"b-\", \"c-\", \"m-\", \"y-\", \"k-\"]\n",
        "    if rgbonly:\n",
        "        styles = styles[:3]\n",
        "    for y, style in zip(data, styles):\n",
        "        plt.plot(x, y, style, lw=2)\n",
        "    ax = plt.gca()\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, 1)\n",
        "    plt.tick_params(axis='both', which='both', labelbottom=False,\n",
        "                    labelleft=False)\n",
        "    fig.tight_layout(pad=0)\n",
        "    fig.canvas.draw()\n",
        "    bin = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
        "    w, h = fig.canvas.get_width_height()\n",
        "    plt.close()\n",
        "    return bin.reshape([h, w, 3])\n",
        "\n",
        "\n",
        "def make_test_image(samples, batch_size):\n",
        "    a = np.linspace(0, 1, samples, dtype=np.float32)\n",
        "    z = np.zeros_like(a)\n",
        "    im = np.stack([a, z, z,\n",
        "                   z, a, z,\n",
        "                   z, z, a,\n",
        "                   z, a, a,\n",
        "                   a, z, a,\n",
        "                   a, a, z,\n",
        "                   a, a, a])\n",
        "    im = im.reshape([7, 3, samples])\n",
        "    im = im.transpose([1, 0, 2])\n",
        "    im = np.tile(im[None, :], [batch_size, 1, 1, 1])\n",
        "    return im\n",
        "\n",
        "\n",
        "def plots_from_test_image(im, height, width, rgbonly=False):\n",
        "    channels = [im[:, 0, 0, :],\n",
        "                im[:, 1, 1, :],\n",
        "                im[:, 2, 2, :]]\n",
        "    channels.append((channels[1] + channels[2]) / 2)\n",
        "    channels.append((channels[0] + channels[2]) / 2)\n",
        "    channels.append((channels[0] + channels[1]) / 2)\n",
        "    channels.append((channels[0] + channels[1] + channels[2]) / 3)\n",
        "    im = np.stack(channels, 1)\n",
        "    n = im.shape[0]\n",
        "    pls = [make_plots(im[i, :], height, width, rgbonly=rgbonly) for i in range(n)]\n",
        "    return np.stack(pls, 0).transpose([0, 3, 1, 2]) / 255.0\n",
        "\n",
        "\n",
        "def _main():\n",
        "    data = np.outer(np.arange(3, 10), np.arange(11)) / 60.0\n",
        "    # data = np.random.rand(7, 10)\n",
        "    im = make_plots(data, 256, 256)\n",
        "    print(im.shape, im.dtype)\n",
        "    plt.imshow(im)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    _main()"
      ],
      "metadata": {
        "id": "x0Bd_GvkKRu7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "a398c173-1a17-48c4-9174-065469e60246"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3) uint8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms, utils\n",
        "import os,sys\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Helper for the creation of module-global constant tensors\n",
        "def _t(data):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    return torch.tensor(data, requires_grad=False, dtype=torch.float32, device=device)\n",
        "\n",
        "\n",
        "# Helper for color matrix multiplication\n",
        "def _mul(coeffs, image):\n",
        "    coeffs = coeffs.to(image.device).view(3, 3, 1, 1)\n",
        "    return torch.nn.functional.conv2d(image, coeffs)\n",
        "\n",
        "\n",
        "_RGB_TO_XYZ = {\n",
        "    \"srgb\": _t([[0.4124564, 0.3575761, 0.1804375],\n",
        "                [0.2126729, 0.7151522, 0.0721750],\n",
        "                [0.0193339, 0.1191920, 0.9503041]]),\n",
        "\n",
        "    \"prophoto\": _t([[0.7976749, 0.1351917, 0.0313534],\n",
        "                    [0.2880402, 0.7118741, 0.0000857],\n",
        "                    [0.0000000, 0.0000000, 0.8252100]])\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "_XYZ_TO_RGB = {\n",
        "    \"srgb\": _t([[3.2404542, -1.5371385, -0.4985314],\n",
        "                   [-0.9692660, 1.8760108, 0.0415560],\n",
        "                   [0.0556434, -0.2040259, 1.0572252]]),\n",
        "\n",
        "    \"prophoto\": _t([[ 1.3459433, -0.2556075, -0.0511118],\n",
        "                    [-0.5445989,  1.5081673,  0.0205351],\n",
        "                    [0.0000000,  0.0000000,  1.2118128]])\n",
        "    }\n",
        "\n",
        "\n",
        "WHITE_POINTS = {item[0]: _t(item[1:]).view(1, 3, 1, 1) for item in [\n",
        "    (\"a\", 1.0985, 1.0000, 0.3558),\n",
        "    (\"b\", 0.9807, 1.0000, 1.1822),\n",
        "    (\"e\", 1.0000, 1.0000, 1.0000),\n",
        "    (\"d50\", 0.9642, 1.0000, 0.8251),\n",
        "    (\"d55\", 0.9568, 1.0000, 0.9214),\n",
        "    (\"d65\", 0.9504, 1.0000, 1.0888),\n",
        "    (\"icc\", 0.9642, 1.0000, 0.8249)\n",
        "]}\n",
        "\n",
        "\n",
        "_EPSILON = 0.008856\n",
        "_KAPPA = 903.3\n",
        "_XYZ_TO_LAB = _t([[0.0, 116.0, 0.], [500.0, -500.0, 0.], [0.0, 200.0, -200.0]])\n",
        "_LAB_TO_XYZ = _t([[1.0 / 116.0, 1.0 / 500.0, 0], [1.0 / 116.0, 0, 0], [1.0 / 116.0, 0, -1.0 / 200.0]])\n",
        "_LAB_OFF = _t([16.0, 0.0, 0.0]).view(1, 3, 1, 1)\n",
        "\n",
        "\n",
        "def apply_gamma(rgb, gamma=\"srgb\"):\n",
        "    \"\"\"Linear to gamma rgb.\n",
        "    Assume that rgb values are in the [0, 1] range (but values outside are tolerated).\n",
        "    gamma can be \"srgb\", a real-valued exponent, or None.\n",
        "    >>> apply_gamma(torch.tensor([0.5, 0.4, 0.1]).view([1, 3, 1, 1]), 0.5).view(-1)\n",
        "    tensor([0.2500, 0.1600, 0.0100])\n",
        "    \"\"\"\n",
        "    if gamma == \"srgb\":\n",
        "        T = 0.0031308\n",
        "        rgb1 = torch.max(rgb, rgb.new_tensor(T))\n",
        "        return torch.where(rgb < T, 12.92 * rgb, (1.055 * torch.pow(torch.abs(rgb1), 1 / 2.4) - 0.055))\n",
        "    elif gamma is None:\n",
        "        return rgb\n",
        "    else:\n",
        "        return torch.pow(torch.max(rgb, rgb.new_tensor(0.0)), 1.0 / gamma)\n",
        "\n",
        "\n",
        "\n",
        "def remove_gamma(rgb, gamma=\"srgb\"):\n",
        "    \"\"\"Gamma to linear rgb.\n",
        "    Assume that rgb values are in the [0, 1] range (but values outside are tolerated).\n",
        "    gamma can be \"srgb\", a real-valued exponent, or None.\n",
        "    >>> remove_gamma(apply_gamma(torch.tensor([0.001, 0.3, 0.4])))\n",
        "    tensor([0.0010,  0.3000,  0.4000])\n",
        "    >>> remove_gamma(torch.tensor([0.5, 0.4, 0.1]).view([1, 3, 1, 1]), 2.0).view(-1)\n",
        "    tensor([0.2500, 0.1600, 0.0100])\n",
        "    \"\"\"\n",
        "    if gamma == \"srgb\":\n",
        "        T = 0.04045\n",
        "        rgb1 = torch.max(rgb, rgb.new_tensor(T))\n",
        "        return torch.where(rgb < T, rgb / 12.92, torch.pow(torch.abs(rgb1 + 0.055) / 1.055, 2.4))\n",
        "    elif gamma is None:\n",
        "        return rgb\n",
        "    else:\n",
        "        res = torch.pow(torch.max(rgb, rgb.new_tensor(0.0)), gamma) + \\\n",
        "              torch.min(rgb, rgb.new_tensor(0.0)) # very important to avoid vanishing gradients\n",
        "        return res\n",
        "\n",
        "\n",
        "def rgb2xyz(rgb, gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to XYZ conversion.\n",
        "    rgb:  Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> rgb2xyz(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> rgb2xyz(torch.tensor([0., 0.75, 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.1868,  0.3737,  0.0623])\n",
        "    >>> rgb2xyz(torch.tensor([0.4, 0.8, 0.2]).view(1, 3, 1, 1), gamma_correction=None).view(-1)\n",
        "    tensor([0.4871,  0.6716,  0.2931])\n",
        "    >>> rgb2xyz(torch.ones(2, 3, 4, 5)).size()\n",
        "    torch.Size([2, 3, 4, 5])\n",
        "    >>> xyz2rgb(torch.tensor([-1, 2., 0.]).view(1, 3, 1, 1), clip_rgb=True).view(-1)\n",
        "    tensor([0.0000,  1.0000,  0.0000])\n",
        "    >>> rgb2xyz(torch.tensor([0.4, 0.8, 0.2]).view(1, 3, 1, 1), gamma_correction=None, space='prophoto').view(-1)\n",
        "    tensor([0.4335,  0.6847,  0.1650])\n",
        "    \"\"\"\n",
        "    if clip_rgb:\n",
        "        rgb = torch.clamp(rgb, 0, 1)\n",
        "    rgb = remove_gamma(rgb, gamma_correction)\n",
        "    return _mul(_RGB_TO_XYZ[space], rgb)\n",
        "\n",
        "\n",
        "def xyz2rgb(xyz, gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"XYZ to sRGB conversion.\n",
        "    rgb:  Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> xyz2rgb(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> xyz2rgb(torch.tensor([0.04, 0.02, 0.05]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.3014,  0.0107,  0.2503])\n",
        "    >>> xyz2rgb(torch.ones(2, 3, 4, 5)).size()\n",
        "    torch.Size([2, 3, 4, 5])\n",
        "    >>> xyz2rgb(torch.tensor([-1, 2., 0.]).view(1, 3, 1, 1), clip_rgb=True).view(-1)\n",
        "    tensor([0.0000,  1.0000,  0.0000])\n",
        "    \"\"\"\n",
        "    rgb = _mul(_XYZ_TO_RGB[space], xyz)\n",
        "    if clip_rgb:\n",
        "        rgb = torch.clamp(rgb, 0, 1)\n",
        "    rgb = apply_gamma(rgb, gamma_correction)\n",
        "    return rgb\n",
        "\n",
        "\n",
        "def _lab_f(x):\n",
        "    x1 = torch.max(x, x.new_tensor(_EPSILON))\n",
        "    return torch.where(x > _EPSILON, torch.pow(x1, 1.0 / 3), (_KAPPA * x + 16.0) / 116.0)\n",
        "\n",
        "\n",
        "def xyz2lab(xyz, white_point=\"d65\"):\n",
        "    \"\"\"XYZ to Lab conversion.\n",
        "    xyz: Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> xyz2lab(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> xyz2lab(torch.tensor([0.4, 0.2, 0.1]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([51.8372,  82.3018,  26.7245])\n",
        "    >>> xyz2lab(torch.tensor([1., 1., 1.]).view(1, 3, 1, 1), white_point=\"e\").view(-1)\n",
        "    tensor([100., 0., 0.])\n",
        "    \"\"\"\n",
        "    xyz = xyz / WHITE_POINTS[white_point].to(xyz.device)\n",
        "    f_xyz = _lab_f(xyz)\n",
        "    return _mul(_XYZ_TO_LAB, f_xyz) - _LAB_OFF.to(xyz.device)\n",
        "\n",
        "\n",
        "def _inv_lab_f(x):\n",
        "    x3 = torch.max(x, x.new_tensor(_EPSILON)) ** 3\n",
        "    return torch.where(x3 > _EPSILON, x3, (116.0 * x - 16.0) / _KAPPA)\n",
        "\n",
        "\n",
        "def lab2xyz(lab, white_point=\"d65\"):\n",
        "    \"\"\"lab to XYZ conversion.\n",
        "    lab: Bx3xHxW\n",
        "    return: Bx3xHxW\n",
        "    >>> lab2xyz(torch.tensor([0., 0., 0.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.,  0.,  0.])\n",
        "    >>> lab2xyz(torch.tensor([100., 0., 0.]).view(1, 3, 1, 1), white_point=\"e\").view(-1)\n",
        "    tensor([1.,  1.,  1.])\n",
        "    >>> lab2xyz(torch.tensor([50., 25., -30.]).view(1, 3, 1, 1)).view(-1)\n",
        "    tensor([0.2254,  0.1842,  0.4046])\n",
        "    \"\"\"\n",
        "    f_xyz = _mul(_LAB_TO_XYZ, lab + _LAB_OFF.to(lab.device))\n",
        "    xyz = _inv_lab_f(f_xyz)\n",
        "    return xyz * WHITE_POINTS[white_point].to(lab.device)\n",
        "\n",
        "\n",
        "def rgb2lab(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to Lab conversion.\"\"\"\n",
        "    lab = xyz2lab(rgb2xyz(rgb, gamma_correction, clip_rgb, space), white_point)\n",
        "    return lab\n",
        "\n",
        "\n",
        "def lab2rgb(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"Lab to sRGB conversion.\"\"\"\n",
        "    return xyz2rgb(lab2xyz(rgb, white_point), gamma_correction, clip_rgb, space)\n",
        "\n",
        "def lab2lch(lab):\n",
        "    \"\"\"Lab to LCH conversion.\"\"\"\n",
        "    l = lab[:, 0, :, :]\n",
        "    c = torch.norm(lab[:, 1:, :, :], 2, 1)\n",
        "    h = torch.atan2(lab[:, 2, :, :], lab[:, 1, :, :])\n",
        "    h = h * (180 / 3.141592653589793)\n",
        "    h = torch.where(h >= 0, h, 360 + h)\n",
        "    return torch.stack([l, c, h], 1)\n",
        "\n",
        "\n",
        "def rgb2lch(rgb, white_point=\"d65\", gamma_correction=\"srgb\", clip_rgb=False, space=\"srgb\"):\n",
        "    \"\"\"sRGB to LCH conversion.\"\"\"\n",
        "    lab = rgb2lab(rgb, white_point, gamma_correction, clip_rgb, space)\n",
        "    return lab2lch(lab)\n",
        "\n",
        "def squared_deltaE(lab1, lab2):\n",
        "    \"\"\"Squared Delta E (CIE 1976).\n",
        "    lab1: Bx3xHxW\n",
        "    lab2: Bx3xHxW\n",
        "    return: Bx1xHxW\n",
        "    \"\"\"\n",
        "    return torch.sum((lab1 - lab2) ** 2, 1, keepdim=True)\n",
        "\n",
        "\n",
        "def deltaE(lab1, lab2):\n",
        "    \"\"\"Delta E (CIE 1976).\n",
        "    lab1: Bx3xHxW\n",
        "    lab2: Bx3xHxW\n",
        "    return: Bx1xHxW\n",
        "    >>> lab1 = torch.tensor([100., 75., 50.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([50., 50., 100.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE(lab1, lab2).item()\n",
        "    75.0\n",
        "    \"\"\"\n",
        "    return torch.norm(lab1 - lab2, 2, 1, keepdim=True)\n",
        "\n",
        "\n",
        "def squared_deltaE94(lab1, lab2):\n",
        "    \"\"\"Squared Delta E (CIE 1994).\n",
        "    Default parameters for the 'Graphic Art' version.\n",
        "    lab1: Bx3xHxW   (reference color)\n",
        "    lab2: Bx3xHxW   (other color)\n",
        "    return: Bx1xHxW\n",
        "    \"\"\"\n",
        "    diff_2 = (lab1 - lab2) ** 2\n",
        "    dl_2 = diff_2[:, 0:1, :, :]\n",
        "    c1 = torch.norm(lab1[:, 1:3, :, :], 2, 1, keepdim=True)\n",
        "    c2 = torch.norm(lab2[:, 1:3, :, :], 2, 1, keepdim=True)\n",
        "    dc_2 = (c1 - c2) ** 2\n",
        "    dab_2 = torch.sum(diff_2[:, 1:3, :, :], 1, keepdim=True)\n",
        "    dh_2 = torch.abs(dab_2 - dc_2)\n",
        "    de_2 = (dl_2 +\n",
        "            dc_2 / ((1 + 0.045 * c1) ** 2) +\n",
        "            dh_2 / ((1 + 0.015 * c1) ** 2))\n",
        "    return de_2\n",
        "\n",
        "\n",
        "def deltaE94(lab1, lab2):\n",
        "    \"\"\"Delta E (CIE 1994).\n",
        "    Default parameters for the 'Graphic Art' version.\n",
        "    lab1: Bx3xHxW   (reference color)\n",
        "    lab2: Bx3xHxW   (other color)\n",
        "    return: Bx1xHxW\n",
        "    >>> lab1 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([80., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE94(lab1, lab2).item()\n",
        "    20.0\n",
        "    >>> lab1 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([100., 20., 0.]).view(1, 3, 1, 1)\n",
        "    >>> deltaE94(lab1, lab2).item()\n",
        "    20.0\n",
        "    >>> lab1 = torch.tensor([100., 0., 10.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([100., 0., 0.]).view(1, 3, 1, 1)\n",
        "    >>> round(deltaE94(lab1, lab2).item(), 4)\n",
        "    6.8966\n",
        "    >>> lab1 = torch.tensor([100., 75., 50.]).view(1, 3, 1, 1)\n",
        "    >>> lab2 = torch.tensor([50., 50., 100.]).view(1, 3, 1, 1)\n",
        "    >>> round(deltaE94(lab1, lab2).item(), 4)\n",
        "    54.7575\n",
        "    \"\"\"\n",
        "    # The ReLU prevents from NaNs in gradient computation\n",
        "    sq = torch.nn.functional.relu(squared_deltaE94(lab1, lab2))\n",
        "    return torch.sqrt(sq)\n",
        "\n",
        "\n",
        "def _check_conversion(**opts):\n",
        "    \"\"\"Verify the conversions on the RGB cube.\n",
        "    >>> _check_conversion(white_point='d65', gamma_correction='srgb', clip_rgb=False, space='srgb')\n",
        "    True\n",
        "    >>> _check_conversion(white_point='d50', gamma_correction=1.8, clip_rgb=False, space='prophoto')\n",
        "    True\n",
        "    \"\"\"\n",
        "    for r in range(0, 256, 15):\n",
        "        for g in range(0, 256, 15):\n",
        "            for b in range(0, 256, 15):\n",
        "                rgb = torch.tensor([r / 255.0, g / 255.0, b / 255.0]).view(1, 3, 1, 1)\n",
        "                lab = rgb2lab(rgb, **opts)\n",
        "                rgb2 = lab2rgb(lab, **opts)\n",
        "                de = deltaE(rgb, rgb2).item()\n",
        "                if de > 2e-4:\n",
        "                    print(\"Conversion failed for RGB:\", r, g, b, \" deltaE\", de)\n",
        "                    return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def _check_gradients():\n",
        "    \"\"\"Verify some borderline gradient computation\n",
        "    >>> a = torch.zeros(1, 3, 1, 1, requires_grad=True)\n",
        "    >>> b = torch.zeros(1, 3, 1, 1, requires_grad=True)\n",
        "    >>> deltaE(a, b).backward()\n",
        "    >>> torch.any(torch.isnan(a.grad)).item()\n",
        "    0\n",
        "    >>> torch.any(torch.isnan(b.grad)).item()\n",
        "    0\n",
        "    >>> deltaE94(a, b).backward()\n",
        "    >>> torch.any(torch.isnan(a.grad)).item()\n",
        "    0\n",
        "    >>> torch.any(torch.isnan(b.grad)).item()\n",
        "    0\n",
        "    \"\"\"\n",
        "    return True\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import doctest\n",
        "    doctest.testmod(optionflags=doctest.NORMALIZE_WHITESPACE)\n",
        "    print(\"Test completed\")"
      ],
      "metadata": {
        "id": "4obanjblKV5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65816edf-bc53-4745-d9d3-685b44585c67"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.7/doctest.py\", line 1487, in run\n",
            "    sys.settrace(save_trace)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "223nldoe33wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import collections\n",
        "\n",
        "\n",
        "class Display:\n",
        "    \"\"\"Write on terminal statistics in a fancy way.\n",
        "    Colors are used to signal variations in the data.\n",
        "    Example:\n",
        "    \n",
        "    display = Display(\"Step {step}/{}   loss: {loss:.2f}\")\n",
        "    display.disp(10, 100, loss=3.14159)\n",
        "    It would print the message:\n",
        "    Step 10/100    loss 3.14\n",
        "    with \"3.14\" colored according to historical variation of the loss\n",
        "    value.\n",
        "    Named fields (such as \"loss\") are tracked and displayed in color.\n",
        "    Unnamed fields are not tracked.  \"step\" is a special untracked field,\n",
        "    and \"steps_s\" is a tracked field that is automatically computed.\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, format_string):\n",
        "        \"\"\"Create the display object.\n",
        "        The format string encodes how information should be displayed.\n",
        "        \"\"\"\n",
        "        self.fmt = format_string\n",
        "        self.vars_ = collections.defaultdict(_DisplayVar)\n",
        "        self.steps_s = _DisplayVar()\n",
        "        self.last_step = None\n",
        "        self.last_time = None\n",
        "\n",
        "    def message(self, step, *fields, **data):\n",
        "        \"\"\"Compose a message with the given information.\"\"\"\n",
        "        self._update_steps_s(step)\n",
        "        d = dict((k, self._update_var(k, v)) for (k, v) in data.items())\n",
        "        return self.fmt.format(*fields, step=step, steps_s=self.steps_s, **d)\n",
        "        \n",
        "    def disp(self, step, *fields, **data):\n",
        "        \"\"\"Print on stdout the given information according the the format of the display.\"\"\"\n",
        "        print(self.message(step, *fields, **data))\n",
        "\n",
        "    def _update_var(self, k, v):\n",
        "        dv = self.vars_[k]\n",
        "        dv.add(v)\n",
        "        return dv\n",
        "\n",
        "    def _update_steps_s(self, step):\n",
        "        tm = time.perf_counter()\n",
        "        if self.last_step is None or self.last_time >= tm:\n",
        "            speed = float(\"nan\")\n",
        "        else:\n",
        "            speed = (step - self.last_step) / (tm - self.last_time)\n",
        "        self.last_time = tm\n",
        "        self.last_step = step\n",
        "        self.steps_s.add(speed)\n",
        "\n",
        "\n",
        "class _DisplayVar:\n",
        "    \"\"\"Track the history of a value and format its last value accordingly.\"\"\"\n",
        "\n",
        "    # Ansi codes for colors and styles\n",
        "    MIN = \"\\x1B[1;32m\"    # bold green\n",
        "    LOW = \"\\x1B[0;32m\"    # green\n",
        "    NORMAL = \"\\x1B[0;33m\" # yellow\n",
        "    HIGH = \"\\x1B[0;31m\"   # red\n",
        "    MAX = \"\\x1B[1;31m\"    # bold red\n",
        "    NAN = \"\\x1B[1;36m\"    # cyan\n",
        "    RESET = \"\\x1B[0m\"     # default style\n",
        "    \n",
        "    def __init__(self, history_len=10):\n",
        "        \"\"\"Initialize the object.\n",
        "        Remembers up to history_len values.\n",
        "        \"\"\"\n",
        "        self.history = collections.deque(maxlen=history_len)\n",
        "        self.minval = self.maxval = None\n",
        "        self.lastvalue = float(\"nan\")\n",
        "        self.state = self.NAN\n",
        "        \n",
        "    def add(self, value):\n",
        "        \"\"\"Add a new value to the series.\"\"\"\n",
        "        self.lastvalue = value\n",
        "        if math.isnan(value):\n",
        "            self.state = self.NAN\n",
        "        elif not self.history:\n",
        "            self.state = self.NORMAL\n",
        "            self.history.append(value)\n",
        "            self.minval = self.maxval = value\n",
        "        else:\n",
        "            _, s = min((min(self.history), self.NORMAL), (value, self.LOW))\n",
        "            _, s = max((max(self.history), s), (value, self.HIGH))\n",
        "            self.maxval, _, s = max((self.maxval, 1, s), (value, 0, self.MAX))\n",
        "            self.minval, _, s = min((self.minval, 0, s), (value, 1, self.MIN))\n",
        "            self.state = s\n",
        "            self.history.append(value)\n",
        "\n",
        "    def __format__(self, spec):\n",
        "        \"\"\"Format the last added value.\"\"\"\n",
        "        s = self.lastvalue.__format__(spec)\n",
        "        return self.state + s + self.RESET\n",
        "    \n",
        "\n",
        "def _demo():\n",
        "    import random\n",
        "    fmt = \"Step: {step:3d}/{}  Loss: {loss:6.3f}  {steps_s:6.4f} steps/s\"\n",
        "    display = Display(fmt)\n",
        "    for step in range(1, 101):\n",
        "        time.sleep(1)\n",
        "        display.disp(step, 100, loss=random.random() * 100)\n",
        "    \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    _demo()\n",
        "    # session = Session(\"model_dir\", save_every=100, save_count=5, state=[model, optimizer], max_epocs=3)\n",
        "    # session.add_state(model)\n",
        "    # session.add_state(optimizer)\n",
        "    # session.restore()\n",
        "    # for x ,y in session.train_loop(loader):\n",
        "    #     session.step\n",
        "    #     session.epoc"
      ],
      "metadata": {
        "id": "TPe1h-hRKhqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0001753-1c4f-4931-9e27-ba543203af39"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step:   1/100  Loss: \u001b[0;33m23.757\u001b[0m  \u001b[1;36m   nan\u001b[0m steps/s\n",
            "Step:   2/100  Loss: \u001b[1;32m20.318\u001b[0m  \u001b[0;33m0.9990\u001b[0m steps/s\n",
            "Step:   3/100  Loss: \u001b[1;31m49.920\u001b[0m  \u001b[1;32m0.9990\u001b[0m steps/s\n",
            "Step:   4/100  Loss: \u001b[0;33m40.978\u001b[0m  \u001b[1;32m0.9981\u001b[0m steps/s\n",
            "Step:   5/100  Loss: \u001b[1;31m52.923\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:   6/100  Loss: \u001b[1;31m79.586\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:   7/100  Loss: \u001b[1;32m 2.756\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:   8/100  Loss: \u001b[0;33m69.337\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:   9/100  Loss: \u001b[0;33m12.969\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  10/100  Loss: \u001b[1;31m98.913\u001b[0m  \u001b[0;33m0.9982\u001b[0m steps/s\n",
            "Step:  11/100  Loss: \u001b[0;33m30.881\u001b[0m  \u001b[1;31m0.9991\u001b[0m steps/s\n",
            "Step:  12/100  Loss: \u001b[0;33m27.986\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  13/100  Loss: \u001b[0;33m96.955\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  14/100  Loss: \u001b[0;33m16.136\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  15/100  Loss: \u001b[0;33m71.056\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  16/100  Loss: \u001b[0;33m21.645\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  17/100  Loss: \u001b[0;33m80.464\u001b[0m  \u001b[1;32m0.9978\u001b[0m steps/s\n",
            "Step:  18/100  Loss: \u001b[0;32m 3.845\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:  19/100  Loss: \u001b[0;33m68.682\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  20/100  Loss: \u001b[0;33m43.295\u001b[0m  \u001b[0;33m0.9980\u001b[0m steps/s\n",
            "Step:  21/100  Loss: \u001b[0;33m71.424\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:  22/100  Loss: \u001b[0;33m45.581\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  23/100  Loss: \u001b[0;33m96.038\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  24/100  Loss: \u001b[0;33m87.061\u001b[0m  \u001b[0;31m0.9988\u001b[0m steps/s\n",
            "Step:  25/100  Loss: \u001b[0;31m97.659\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  26/100  Loss: \u001b[0;33m84.910\u001b[0m  \u001b[0;31m0.9991\u001b[0m steps/s\n",
            "Step:  27/100  Loss: \u001b[0;33m86.739\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  28/100  Loss: \u001b[0;33m47.261\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  29/100  Loss: \u001b[0;32m42.832\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  30/100  Loss: \u001b[0;32m 9.070\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:  31/100  Loss: \u001b[0;33m26.842\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  32/100  Loss: \u001b[0;33m85.517\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:  33/100  Loss: \u001b[0;33m10.977\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  34/100  Loss: \u001b[0;33m38.756\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  35/100  Loss: \u001b[0;33m61.477\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  36/100  Loss: \u001b[0;33m41.144\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  37/100  Loss: \u001b[0;33m78.186\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  38/100  Loss: \u001b[0;31m92.552\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  39/100  Loss: \u001b[0;33m12.878\u001b[0m  \u001b[0;32m0.9981\u001b[0m steps/s\n",
            "Step:  40/100  Loss: \u001b[0;33m11.673\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:  41/100  Loss: \u001b[0;33m63.840\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  42/100  Loss: \u001b[0;32m10.714\u001b[0m  \u001b[1;32m0.9974\u001b[0m steps/s\n",
            "Step:  43/100  Loss: \u001b[0;31m92.581\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  44/100  Loss: \u001b[0;33m61.967\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  45/100  Loss: \u001b[0;33m90.527\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  46/100  Loss: \u001b[0;33m21.713\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  47/100  Loss: \u001b[1;32m 1.254\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  48/100  Loss: \u001b[0;31m95.902\u001b[0m  \u001b[0;33m0.9979\u001b[0m steps/s\n",
            "Step:  49/100  Loss: \u001b[0;33m39.823\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  50/100  Loss: \u001b[0;33m17.126\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  51/100  Loss: \u001b[0;33m26.960\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  52/100  Loss: \u001b[0;33m77.727\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:  53/100  Loss: \u001b[0;33m55.302\u001b[0m  \u001b[0;31m0.9988\u001b[0m steps/s\n",
            "Step:  54/100  Loss: \u001b[0;33m 7.486\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  55/100  Loss: \u001b[0;33m57.201\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  56/100  Loss: \u001b[0;33m95.274\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  57/100  Loss: \u001b[0;33m24.228\u001b[0m  \u001b[0;33m0.9984\u001b[0m steps/s\n",
            "Step:  58/100  Loss: \u001b[0;33m13.230\u001b[0m  \u001b[0;32m0.9978\u001b[0m steps/s\n",
            "Step:  59/100  Loss: \u001b[0;33m85.303\u001b[0m  \u001b[0;33m0.9982\u001b[0m steps/s\n",
            "Step:  60/100  Loss: \u001b[0;33m11.666\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  61/100  Loss: \u001b[0;33m58.164\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  62/100  Loss: \u001b[0;33m69.753\u001b[0m  \u001b[0;32m0.9977\u001b[0m steps/s\n",
            "Step:  63/100  Loss: \u001b[0;33m30.170\u001b[0m  \u001b[0;32m0.9975\u001b[0m steps/s\n",
            "Step:  64/100  Loss: \u001b[0;33m49.185\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  65/100  Loss: \u001b[0;33m62.429\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  66/100  Loss: \u001b[0;33m58.785\u001b[0m  \u001b[0;31m0.9988\u001b[0m steps/s\n",
            "Step:  67/100  Loss: \u001b[0;33m33.788\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  68/100  Loss: \u001b[0;33m79.774\u001b[0m  \u001b[0;31m0.9991\u001b[0m steps/s\n",
            "Step:  69/100  Loss: \u001b[0;33m74.959\u001b[0m  \u001b[0;33m0.9980\u001b[0m steps/s\n",
            "Step:  70/100  Loss: \u001b[0;32m10.396\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  71/100  Loss: \u001b[0;33m25.127\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  72/100  Loss: \u001b[0;33m18.077\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  73/100  Loss: \u001b[0;33m41.169\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  74/100  Loss: \u001b[0;32m 6.249\u001b[0m  \u001b[0;32m0.9978\u001b[0m steps/s\n",
            "Step:  75/100  Loss: \u001b[0;33m19.064\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  76/100  Loss: \u001b[0;33m63.007\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  77/100  Loss: \u001b[0;33m 6.924\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  78/100  Loss: \u001b[0;33m48.803\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  79/100  Loss: \u001b[0;33m14.000\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  80/100  Loss: \u001b[0;33m49.698\u001b[0m  \u001b[0;33m0.9987\u001b[0m steps/s\n",
            "Step:  81/100  Loss: \u001b[0;33m18.110\u001b[0m  \u001b[0;33m0.9980\u001b[0m steps/s\n",
            "Step:  82/100  Loss: \u001b[0;33m14.103\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:  83/100  Loss: \u001b[0;31m83.103\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  84/100  Loss: \u001b[0;31m91.601\u001b[0m  \u001b[0;33m0.9979\u001b[0m steps/s\n",
            "Step:  85/100  Loss: \u001b[0;33m88.334\u001b[0m  \u001b[0;31m0.9988\u001b[0m steps/s\n",
            "Step:  86/100  Loss: \u001b[0;33m82.070\u001b[0m  \u001b[0;33m0.9980\u001b[0m steps/s\n",
            "Step:  87/100  Loss: \u001b[0;33m39.569\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  88/100  Loss: \u001b[0;32m11.925\u001b[0m  \u001b[0;33m0.9980\u001b[0m steps/s\n",
            "Step:  89/100  Loss: \u001b[0;33m64.411\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  90/100  Loss: \u001b[0;33m55.435\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  91/100  Loss: \u001b[0;33m51.012\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  92/100  Loss: \u001b[0;33m89.371\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  93/100  Loss: \u001b[0;33m78.729\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  94/100  Loss: \u001b[0;33m31.592\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:  95/100  Loss: \u001b[0;32m 5.793\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  96/100  Loss: \u001b[0;31m95.415\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step:  97/100  Loss: \u001b[0;33m25.051\u001b[0m  \u001b[0;31m0.9988\u001b[0m steps/s\n",
            "Step:  98/100  Loss: \u001b[0;33m17.933\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n",
            "Step:  99/100  Loss: \u001b[0;33m65.887\u001b[0m  \u001b[0;33m0.9988\u001b[0m steps/s\n",
            "Step: 100/100  Loss: \u001b[0;33m75.394\u001b[0m  \u001b[0;33m0.9981\u001b[0m steps/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class SplineInterpolator(torch.nn.Module):\n",
        "    \"\"\"Module performing spline interpolation.\n",
        "    Splines are defined by a set of n nodes.  x coordinates of the\n",
        "    nodes are assumed to be equispaced in the [0, 1] range.\n",
        "    y coordinates of the nodes are part of the input.\n",
        "    Given a different set of x coordinates, the module compute\n",
        "    the interpolated y coordinates.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, nodes, dtype=torch.float32):\n",
        "        \"\"\"Create the object.\n",
        "        Parameters\n",
        "        ----------\n",
        "        nodes : int\n",
        "            number of nodes.\n",
        "        dtype\n",
        "            type of internal data.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        A = self._precalc(nodes)\n",
        "        self.register_buffer(\"A\", torch.tensor(A, dtype=dtype))\n",
        "\n",
        "    def _precalc(self, n):\n",
        "        # Helper function computing the internal matrix A.\n",
        "        h = 1.0 / (n - 1)\n",
        "        mat = 4 * np.eye(n - 2)        \n",
        "        np.fill_diagonal(mat[1:, :-1], 1)\n",
        "        np.fill_diagonal(mat[:-1, 1:], 1)\n",
        "        A = 6 * np.linalg.inv(mat) / (h ** 2)\n",
        "        z = np.zeros(n - 2)\n",
        "        A = np.vstack([z, A, z])\n",
        "\n",
        "        B = np.zeros([n - 2, n])\n",
        "        np.fill_diagonal(B, 1)\n",
        "        np.fill_diagonal(B[:, 1:], -2)\n",
        "        np.fill_diagonal(B[:, 2:], 1)\n",
        "        A = np.dot(A, B)\n",
        "        return A.T\n",
        "        \n",
        "    def _coefficients(self, y):\n",
        "        # Helper function computing the coefficients of the polynomials\n",
        "        # For the given y coordinates of the nodes.\n",
        "        n = self.A.size(1)\n",
        "        h = 1.0 / (n - 1)\n",
        "        M = torch.mm(y, self.A)\n",
        "        a = (M[:, 1:] - M[:, :-1]) / (6 * h)\n",
        "        b = M[:, :-1] / 2\n",
        "        c = (y[:, 1:] - y[:, :-1]) / h - (M[:, 1:] + 2 * M[:, :-1]) * (h / 6)\n",
        "        return (a, b, c, y[:, :-1])\n",
        "\n",
        "    def _apply(self, x, coeffs):\n",
        "        # Helper function interpolating the splines at x.\n",
        "        # coeffs is the list of coefficients of the polynomials.\n",
        "        n = self.A.size(1)\n",
        "        xv = x.view(x.size(0), -1)\n",
        "        xi = torch.clamp(xv * (n - 1), 0, n - 2).long()\n",
        "        xf = xv - xi.float() / (n - 1)\n",
        "        a, b, c, d = (torch.gather(cc, 1, xi) for cc in coeffs)\n",
        "        z = d + c * xf + b * (xf ** 2) + a * (xf ** 3)\n",
        "        return z.view_as(x)\n",
        "\n",
        "    def forward(self, y, x):\n",
        "        \"\"\"Interpolate values using splines.\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : tensor (b, n)\n",
        "            y coordinates for the nodes (one set for each batch).\n",
        "        x : tensor (b, m1, m2, ..., md)\n",
        "            values to interpolats (one set for each batch).\n",
        "        Returns\n",
        "        -------\n",
        "        tensor (b, m1, m2, ..., md)\n",
        "            interpolated values.\n",
        "        \"\"\"\n",
        "        return self._apply(x, self._coefficients(y))\n",
        "\n",
        "    \n",
        "def _demo():\n",
        "    import matplotlib.pyplot as plt\n",
        "    n = 10\n",
        "    b = 5\n",
        "    sp = SplineInterpolator(n)\n",
        "    y = torch.rand((b, n))\n",
        "    x = torch.rand((b, 20 * n, 10))\n",
        "    z = sp(y, x)\n",
        "    ax = np.linspace(0, 1, n)\n",
        "    for i in range(b):\n",
        "        plt.figure()\n",
        "        plt.plot(ax, y[i, :].cpu().numpy(), 'r.', markersize=25)\n",
        "        plt.plot(x[i, :].cpu().numpy(), z[i, :].cpu().numpy(), 'b.')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    _demo()"
      ],
      "metadata": {
        "id": "mgisoT5VIlPB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "85289138-db18-4724-b85e-4c85abc86bbc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de5hU1ZXof6u7BUVA5BFhxIBGSGhFMTJAGWWYzww+Mj6uySQqfTGG2CbG15gbWp2b3MT5RmjiGHWEhHLykLSPaEwcMjEXZjLharRQyYgPQAMxEiGiBAICyqO79/1jV1F19jndXXRXnVet3/f117VX7Tpnna6uVfustfZaYoxBURRFST51USugKIqiVAY16IqiKClBDbqiKEpKUIOuKIqSEtSgK4qipISGqE48fPhwM3bs2KhOryiKkkh+85vf/MkYMyLoucgM+tixY1m1alVUp1cURUkkIrKxq+fU5aIoipIS1KAriqKkBDXoiqIoKUENuqIoSkpQg64oipIS1KAriqKkBDXoiqLElnPOARHvT1NT1FrFFzXoiqLEjsZGa7yXL/c/98AD9rnRoyGXC1+3OKMGXVGU2NDSYo31unU9z928Gc44A7LZ6uuVFNSgK4oSC8aOhQULDv11V19tV/SKGnRFUWJAYyNs7HJDe8+sWwf9+lVOn6SiBl1RlEjJZrt3scycCcbA3LkwZEjX8w4cgMMPr7x+SUKi6ik6efJko8W5FEUZNQq2bPHL6+uhvT34NUceCe+9F/zcmDHwxhsVUy92iMhvjDGTg57TFbqiKJGRzQYb8zFjujbmAHv2wKxZwc9t3GjTHWsRNeiKokRCLmcDmi4zZ5a3wm5rg8WLg59bvrw2s1/UoCuKEgnXXOOXDRwIy5aVf4zm5q5X6kHHTztq0BVFCZ1sFlav9st7Y4Tb2mDKFL+8o6P2Nh5pUFRRlNAZPBh27fLKTjwR1q/v/TGDAqWjR8Obb/b+mHFEg6KKosSGlha/MQdYsqRvx92zxy/btMmer1ZQg64oSqjce69fNmsWZDJ9P3aQP33BgtpxvfRo0EXkeyLyjoi80sXzIiL3iMgGEXlJRD5aeTUVRUkDLS1+t8jgwdYPXgna2mDQIL98xozKHD/ulLNC/wFwbjfPnweMy/80A9/uu1qKoqSRf/5nv+yb36zsOe64wy/bv9/Q8rm34amn4MUXu09yTzA9GnRjzJPA9m6mXAQsMZaVwBARGVUpBRVFSQdNTTbzpJSGBpt6WEmam2Ho0MKomPRx5/eHwAUXwJlnwsiRcNttsL0705Y8KuFDPxYojSNvyst8iEiziKwSkVVbt26twKkVRUkKS5f6ZZ/5THXOtW0bCJ0eWTv9aNz5JOzebSfMmwcnndS31JqYEWpQ1BiTNcZMNsZMHjFiRJinVhQlYtwM6SOOqJzv3Mf27XxlQCH6agABYB0TaeF2K967F95+G6ZPT81KvRIGfTNwXMl4dF6mKEqt094OL75Iy6w/sHu3odQFMnFiFc977720drYwgtJCMdao/4RPFkXGwI4dsHBhFZUJj0oY9KXA7Hy2yzRgpzHmrQocV1GUpLJ9u/VRjxwJZ57JHQ8WwmqCNeqGOXOqdO72drjnHti7l3/jEqDj4DkBhvIn7/y9e+Huu/0O/gRSTtriQ0AO+LCIbBKROSLyBRH5Qn7KE8DrwAbgPqAGKygoinKQ9eutb3rePNi2jabdC+mkwTNF6KT5r6vku16zBvbtAyDDSr7AfQfPCvAcmaLbpcD+/fBKYGZ2omjoaYIx5rIenjfAlyqmkaIoyWX7djjrLHjnnYNO88cOujjk4LQT2QDTZ1jjW0xJqQzvvmuLqeeZzRK+Q6Gso71DWMDNXMxSMqy04ro6+7qEoztFFUWpHPfeCzt3eiKgQmk01Lo+7uez1fNdDx7scZ9kWMnhvF8ywX6xLOArRVFnp31dwlGDrihKZSjxXZcyEG/hlnGstyvjavmuTzoJ+vf3iD7JY/lHxS+Xn3NecUL//nDyyZXVIwLUoCuKUhlKfNcFWridrYz0yM7mv4qDaviuGxrg+us9DUbbuIJ6DnimHeBwmrjfzrv+eo+bJqmoQVcUpTI4vmuALIVtoMXsltmUlFWslu/62mttR2kp+u0v5eH8o2Je+sNcaud9KR1hQDXoSnrI5zynvV5HbHF81zmmsYOjvVPYWQxEQvV810OHwpNPwjHHHFypt3EFOLtHOziM7JdWVz4wGxFq0JXk4+Q8p71eR2xxfNc26CiUZreMdvccVtN3PW6cdQPdeisMGwaDBjGQ0qLpVq8b/umY6pw/AtSgK8nGyXlm926bZZHieh2xxfFdv8b4kidtMPIG7i6KwvBdDx0KX/2q3eL/1FNcc/kOjz4g7N2bnobSatCV5FLIeX77bV9mxUFSWK8j1pT4rkc4OzJP5QWa+Vc7EAnXd11fD6eeSusDH2TgQO9dA8BjjwW/LGmoQVeSS0DOc5bP08jLnMTLZPm8FaasXkesyfuuc0efz685My80NNDOtwv7Dw8/3Pq2n3wyEt/18uV+WVr6jmqTaCWZtLdbH/m2bQdFg9nGLicIN5LNfINv2JXhsGF2tZ6C9LS481dnHODJXAOF7JZJdS/xwpFnWZ/59dfblXmEgcipU+G557yyuXOhtTUafQ4FbRKtpA8n57mBvSXGvHhLvYVjuZqsrd2RknodSeC/Xz6MUrfGGwMabfbRli3Wpx1xVklQYbCgbkpJQw26kkxKcp4Hs40O+uWfKBiRQq5xYZt3C7nOqamo1xF3cjkbky4i1PU7DE49NTZ3R0FdklJQbFENupJQ8jnP5/BzZ2VeWnPblMiFK/YsSkW9jrizYIFfNnKkXxY1Qd8tU6eGr0clUYOuJJN8zvNyZuYFBWMO0Mkg/px/XIwRredD5HYlv15H3HntNb/shhvC16Mnvvxlv8z1qycNNehKMmloYGr/FwB3mWUwNPAuwziM0lTG/Cr9c/G45U8zf3L6R4wbV/lG0JWgqwBoLheuHpVEDbqSWFZtKfQiL67Ox/D6wefv5fr8o5JV+vr0bCKJI01N4PZ/P/vsaHQph3Hj/LJPfzp8PSqFGnQlkeRy0Nnp/vt28AbFT2gz/8pMKSQdFwsy3XJLKCrWJD/+sV82e3b4epTL/ff7ZZs2JXeVrgZdSSRFI1FMjZtSvxoGDYKjjrK/hw9n2TeeY9jRnZ5527dDS0uo6tYMbqZIQwNkMtHoUg6ZDPTr55cHBXaTgBp0JZH8/veuRJhz72k21/lnP/PkPN8+3+83/973QlGzpsjl/AUuS0qSx5Ybb/TL/uM/wtejEqhBVxJHS4t/JThhAjR/wdbr4KyzPDnPzc1+w+LNk1YqwZIlftlHPxq+HodKa6sty17Knj3JjLWoQVcSh/tBq6+HtWu7f82gQd5xmirsxYWg92D+/PD16A3HBFTQ/e53w9ejr6hBVxKHu7o+4oieX3PllX5ZEj+wccatqjB0aLz956V8/et+2W9/G7oafUYNupIoWlr8ftpybutbW+HEE72y/fsrp1etk8v5qxMn6e8b5JbbsSN5d3Fq0JVE8YMf+GXl3tYvWeLd7r16dfI+sHElyH8+fHj4evSFT37SL0vaXZwadCVRuH0sDuW2PpOB00/3ytLS2CBqgvznScv3b2uDESO8siTdZYAadCVBZLP+YonTpx/aMdyyqZMm9U0nxeJ+0Y4dG8/t/j3hrtJffDFZm4zKMugicq6IvCYiG0Tk5oDnPygivxKRF0TkJRE5v/KqKrVO0O3v3LmHdozmZvuaujrbBe1f/iVZH9ikkLTVeYHZs+3/RQFj4GafxYsvPRp0EakHFgLnAY3AZSLS6Ez738AjxpjTgEuBRZVWVFHc299Jk3qXRTFkCHR22g/r++/DihUVUa9maWryVimcMiWZq3Ow/0+u7//VV6PRpTeUs0KfAmwwxrxujNkPPAxc5MwxQKHQ9FHAHyunoqLYVfTq1V7Z2LG9O5ZrwNWg941HH/WO3fcpabgpru+8k5y7uHIM+rFAaQvVTXlZKV8HmkRkE/AEcF3QgUSkWURWiciqrW5JNkXphqDb3t42TXBb2a5c2bvjKBZ3127SO/+0tsLo0V7ZNddEo8uhUqmg6GXAD4wxo4HzgR+KiO/YxpisMWayMWbyCDecrCjd8NJLfllvq/idd553vHt3clZgccTt/JOE+i09sXOnd7x6dTL+R8ox6JuB40rGo/OyUuYAjwAYY3LA4UDCslCVOOP6z/v37/0uxLY2b3aLiLpdeks2639vytm5G3eC2tMloQJjOQb9eWCciBwvIv2wQc+lzpw/AGcDiMgErEFXn4pSMdzdoQ0NfTveokXW8NTV2Z9hw/p2vFolKPPoc58LX49KExTUTUIpgB4NujGmHbgWWAasw2azrBGR20Tkwvy0LwNXiciLwEPAZ40xJviIinJoBK0CL764b8fMZOCuu6wx7+iwJVSTcEsdN/7opD8MHNh1a7ck0doKxzqRwiTsfC1rnWOMeQIb7CyVfa3k8VrgY5VVTVEs8+Z5xwMGWLdJX9m2zRpzY+zGmBUrklNMKi64/UPdMrRJ5oIL4DvfKY6HDo1Ol3JJ0Z9fSSvVMho7dlhjDvb3jh2VOW6tkM36d4hOmxaNLtVg9myva2/p0vjfxalBV2JP//7e8cCBlTmuW1AqaYWYoiaoDs6MGaGrUTUyGTj55OK4szP+6Ytq0JVYE1SWtVKrQHdFvm1b/FdgccKtg1Nfny6DDv67w7inL6pBV2LNkiVFtwjYFMNDrd/SFR/5SPD5lPJ44AHv+Oij0xeDuPxyvyzOq3Q16EqsccuynnJK5YzGIq041CfcDJdt26LRo5q0tvpz0ntqdxglatCVWOPm/layPnUm41/tDx4cPFfxkst575zA37c1LQTVSI+r20UNuhJbslnYssUr+/CHK3uOIUO85VLvvDO+H9Y4EeSa+uY3w9cjDL7xDe84zjuL1aArscXNOqmk/7zAjBne1LSOjvh+WOPM9OnJLZnbE83NMHNmcWwMLF4cnT7doQZdiS1ukadTT6180C2Tgb//++LYGC0DUA6nneYdz5oVjR5RsXEjnHNO1Fr4UYOuxBa33Vy1/NvueV54oTrnSRO/+EXxcV1dOgOipQQ1kP7lL8PXoyfUoCuxJKihhZsTXClcP707Vrxks/D448VxGvPPXYLcSZ2d4evRE2rQlVgSFHQbP74653IbZfS2cUat4NbWGTYsffnnQbhZPJXasVxJ1KArsSSoi1ClA6IFZs8ulhcQgV27qnOetODusHXruaSVL37RO77wwuB5UaIGXYklb7zhHQ8aVL1VYCYDn/qUfWyM3QHZ0lKdc6UBNy+7t71dk0Zrqw3+FtJcf/KT+KW4qkFXYslRR3nH1S5d6qYqutvaFUsuB7/7nVeWpgqLPXHSScVqn++/H78uRmrQlVjymc94x7feWt3zfehD3nHpZiOlyJIl3mBgXV3ve7smkRkzvOWbH3/cBonjghp0JXbkct5dh3PnVn/Tyvz53g/qpk3qdgnCzQA688zaCIgWyGTgsMO8sq98JRpdglCDrsSOK67w1gn56U+rf85MBkaN8sp+8pPqnzdpuBlAjY3R6BEl77/vHccpiK4GXYkdbkDUHVcLd7fjJZeEc94k4W7ucneM1gJx7jWqBl2JHQMGeMdDhoRz3tZWW7Ojrs7Wd9m8OZzzJoVcDu64wyurxV21jzzijbHs2BGfbBc16EqsyOX8W/GPPz6cc2ezsHy5Dfq1t9tMl6amcM6dBNyAaK2SycBFFxXHBw7AzTdHp08patCVWLFihb/O9pw54Zw7qEdmac2SWidos1ctZbiU4sYSnnwyHtkuatCVWOFWOpw1K7yyrEEFmE48MZxzJwG3Q9GQIbWV4VJK0BfZXXeFr4eLGnQlVrg+2TC74DQ3+7M2wvLfJwH3zimOtUzCIpPxb3Z7++1odClFDboSK9x+jWFXPvzbv/WO3W3utUouV71ql0nFXWxs3x59cFQNuhIbcjl4+mmvLOzKh+6K/KGHov+QxoGg2Mbll0eiSmwIStkMqhIaJmrQldiwYoU3i6K+Pvygm7u1u7MzfvU6osCtsDhlik3zrGWCqn/+53+Gr0cpZRl0ETlXRF4TkQ0iEpigIyKfFpG1IrJGRB6srJpKLTBsmHcV+OUvhx90y2TgIx/xytxgYC3yox95x3HwF0dNJuNvk/jmm9HoUqBHgy4i9cBC4DygEbhMRBqdOeOAW4CPGWNOAm6sgq5Kytm2rbhhQyS6gKTrR097N55ycFvM7dwZjR5xw/3y37cvWhddOSv0KcAGY8zrxpj9wMPARc6cq4CFxpg/Axhj3qmsmkotsGNHcYVujP82PyzcfOug/OtaIpeD3bu9slNOiUaXuLFokV8W5Sajcgz6sUDpjcSmvKyU8cB4EXlaRFaKyLlBBxKRZhFZJSKrtm7d2juNldTi9hB1x2Gxbl3341ojKIYwf374esSRTAaOOMIre+aZaHSBygVFG4BxwAzgMuA+EfHdMBtjssaYycaYySM0H0xxmDTJOw7a6BMGEyZ4x24xplrD3RswcmTtbigKwvWjt7dHV3q5HIO+GTiuZDw6LytlE7DUGHPAGPN74LdYA68oZZHLwbe+ZR+LhFMDvSvmz7cZNgVeeaW2Uxf37Ytag3hz1VV+2fe/H74eUJ5Bfx4YJyLHi0g/4FJgqTPncezqHBEZjnXBvF5BPZWUs2CBLXIE1n/+299Gp0smAx/7WHHc3l7bqYv790etQbxpbfVXCN2zJxpdejToxph24FpgGbAOeMQYs0ZEbhORQt/rZcA2EVkL/Ar4ijFmW/ARFcWPmxoYdaqg+4VSq4HRXA7+/GevrNr9XZPIzJne8XvvReN2KcuHbox5whgz3hjzIWPMP+VlXzPGLM0/NsaYm4wxjcaYicaYh6uptJJ+xkXssHPLxNaq2yFoh+gNN0SiSqwJ2mT0YAS7cXSnqBI52Sw895xXFnUS1Gc/6x3HqYlBmERZ/TJJZDL+fRNuqmcYqEFXIue73/XLospwKdDa6s1uMSY+TQzCxK0HH5VvOAm4d3VRLALUoCuR4wbdRo+OxyrQ3Q353/8djR5R8tpr3nHUsY04c8EFflnYiwA16ErkuAbdbUQcFe6Kq9ayPXI5ePVVryys7lFJpK0N+vXzysLelKYGXYkc90PgjqPiAx/wjvfvry0/+jXXeAOicblzijPuYsQNKFcbNehK5MTVoN9yi18Wdb3rMHnd2UniNu9W/Lh3ce+/H+751aArkePexsfltr65GaZPj1qL6HBLHtR6CYRycP3o770X7l2dGnQlciZOhIsvtk0TFi+O1239ccd5x7t2RaNHFLglcws7eZWuaWvz7qEwJty7uobwTqUofnI5OPtse6var5817nHi2We7H6eVbBbecYpgX3JJNLokjSOP9I5/9jP49rfDObeu0JVIWbHCGvOODvt7xYqoNfLiGrETTohGj7Bx9waMHKkt58rFbaa9ebP9ggwDNehKpMyYYVfm9fX2d9y6A7W2eut0LF8e3oczSv7iL7zjadOi0SOJBDXPDto8Vw3UoCuR8vLL1s1ywQXwy1/Gs862W6hr3rxo9AgT123gjpWuaW311yIKa0OWGnQlMrJZuPpqW8fl8cetcY8jbiu8qFrjhclPf+od//zn0eiRVO6/v9gfF2DTJmhqqv551aArkfHYY92P44LbPzPt/TSzWZtuV0pHRzS6JJVMxl8j/Wc/q/551aArkeF2IXRb0MUF13/sthxLG0FfrKedFr4eScd1u4QRUFeDrkRCLgcPO1Xz3fKjccFtVp32wGhQu19tCn3oLFoEdSUW1i0lUQ3UoCuRsGSJ9za+vj5+GS4Fgkr5hpW1EAVuLfopU+IZrI47mQx8/OPF8fLl1fejq0HvDe3t8OKL8NRT9nd7e9QaJY61a73jiRPjazSam/23z2l3u5QS1y/aJPDkk95xteNEatAPhe3b4bbb7C6LM8+0uXZnnmnHt91mny+hqclGunv6CSP6HTf27vWO41KQqytOOsk7TmtfzWzWriRLiasrLAm4JZirXT5BDXq5rF9vP9Xz5tkiF7t32w4Iu3fb8bx5cNJJNF30Lg0N1lA/8EB5h37gATv/Ax+onfKs7qovLgW5umLkyO7HaeH22/0yXaH3HneDVkdHdeMvatDLYft2OOssePtt/9IyT+PeZ5Etm3lg6SA6OnpXBHnrVjjjDBg1qi/Kxp9cDu68M2otDg03yyOtWR9ul6ZBg+LrCksCQSWYqxl/UYNeDvfea//TnWr1OaYxgF0IHaxjIlDYSSC+QxwKW7bYIGFLS58OE1tWrPCHHeKag15g27ZixoIIvPBCtPpUi7FjveMPfSgSNVJDc7NtDFJKNTtfqUHvifZ2uOce38p8MNs4g2d4nyPxGvLC4761KunshAUL/F3X00DQNUXdFLonZsyAww6zj42B++5Lp3vM7bijNVz6jut2UYMeJWvWwL59B4dZPo9wgF0cnZdIyY8p+bEceSQ884w1AkE/EyZ0f/rt2+2KME3Gw13dTp8erxroQWQyMHVqcdzRYb9w00Q2683KaGiA2bOj0yctuPGh116r3udZDXpPvPsu1NeTYxrjeZWryQL1+SdLV+Pm4GOhg5l/uR1jbMy0Ox/k2rVF495doO2MM9KzmWXLFu84KRkjbvjktdei0aNa3HWXd3zsseo/rwRu56uODsOS1j9WJeVZDXpPDB5M486nOYOnWc/4vDDItWKYwMsY6ukcNJRl92065FO99Zbt2NMVV1+djpW6k92ZGNyV1oYN6Xg/Crj9L6VvoSCllAMHKL1zX/vvv+s25bm3qEHvhmwWZNJE1tGI17UCpavyMfwOQz1rOdU+1b8/nHxyr87Z3GxdNF2R9B6XuZzdj5VEmpttq7wCHR3xa8jRF9x8c80/rxDr17P3+Zc8olc6PuxLeWb9+j6fqiyDLiLnishrIrJBRG7uZt4nRcSIyOQ+axYxo0bZFXHxTxTkXulgLvN5g5JthIcfDtdfb9NUekkm40uoOUh7OzQ29vrQkbNkif/akpTTfd55xcednekKWr/+undcC2WCq04+5XlOe+HW2/7zb2cETdxvRXv32pTo6dP7vFLv0aCLSD2wEDgPaAQuExGfSRGRQcANQOK7LtbVuX5e173SyVzmYziMVm4tmSZ2WfOlL1VED2OCb3vXrUtuSqPrPxdJVuDN3SxW7uaxuNPSYsNFpRxxRDS6pIp8ynMz91FHwV9uP9Q/4jPFecbYb9CFC/t0unJW6FOADcaY140x+4GHgYsC5v0j0AoE77xJAOecYw1M8OrYCgewC0OD15CDXZkfc4xNE6hglK+z02YbuNxxR8VOESruAuTUU5MVeFu3rvtxUvnJT/yyG28MX49U0UXKc4FO1/zu3Qt3392n4vPlGPRjgTdLxpvysoOIyEeB44wx3fY1EZFmEVklIqu2uiXdIqax0V/DopT6euGZ/7uLPbfdbe+zBw2Co46yv4cPh1tvtSmObhWnCuAW+AFr6MeOTV6RMLeBbjVzcqvBscd6x/37R6NHpSlNyQRbYTHuqaSxx0l5/jj/kX9knHEJ+/fDK6/0+pR9DoqKSB1wJ/DlnuYaY7LGmMnGmMkjgoouR8SwYd2vtMaMsbYyc85g+OpXrb/rqadsC5KnnrJ+hK9+tWr5d5kMzJrlSg0bN9bTdPqaHouExQm3CNf48cHz4oq70WbTpnSkk7rFx0qDv0ovyac8F1jGJ5jJLziCPczkFyzjE/7X1NX5fV+HQDkGfTNwXMl4dF5WYBBwMrBCRN4ApgFLkxAYLVRD7M7+zZoFb7zhCOvrra/grLPs7z4EQMulra0QPCwEZa0f7oGOy8ju/LuqRMwrTTbrbRZRXw9z50anT28I8vfffXf4elSaNWu84zQFeyNj8GCf+2QZn+A9BgUbc7C33u523UOgHIP+PDBORI4XkX7ApcDSwpPGmJ3GmOHGmLHGmLHASuBCY8yqXmsVAlOndh/QGjrU+tLb2sLTqSfeWrMdofQfxBr1WygpkVfBiHmlcYsSjR+fLP85WH3drBy3/2bSyGa9nwURuzZQ+shJJx26T64PKc9QhkE3xrQD1wLLgHXAI8aYNSJym4hc2OszR0hTk+003xVz58b0H/ree7m87kf5QTFyu53hZPl8cV6FIuaVxq1p8eEPR6NHX3HdLnHthVou8+b5ZVoytwI0NNgU5nK7oVQg5RljTCQ/p59+uomCCRO6qqpiTH29MYsXR6JWzxw4YMywYcaAGcEfDXSW6N5pBrPdf0HDhhnT3h615geZO9erXmz/1j3gXsesWVFr1DcGDvRezxFHRK1Riti2zZiRI40R6drwgH1+5Eg7vweAVaYLu1pTO0UHD+46+Dl0qA18xjayXxIx/zcuyQuLq/R3OYocztKxjxHzSpLLwbe+VRwn+bbebRr90EPJLgHgZhoVqkoqFWDoUJumdswxXa/UK5jyXDMGvV8/2LUr+LkBAxJgXEoi5hlWMoWCBSkESIUr+IH3NX2MmFeSFSuS0xS6J9xSv52ddgdsEmlp8Rv0uLcDTBzjxtkF2a23Vj3luSYMekND1738JkyAPXvC1adXOBHzZ/kY9Xjzztcz3rtK72PEvJIU6omLWGO+cGHyAqIF3Op5SebBB/2yz30ufD1Sz9ChoaQ8p96gjx3b9carmTP93edjS0DE/FIeyj8qpjGexYrihD5GzCtNYQdufT1MnBitLn3F3ReQ1JZ0w4d7xyNGQGtrNLrUBFVOeU6tQW9qsvZs48bg5+fOhWXLwtWpTwREzNu4AvC2Fe+gH428WJmIeQUpuFyMSUeVwrTUdHEzduLeOUrpnlQa9FGj7AcsaFt5fb01KolchVx7rS3+VVKxa8rBWmjFVfo6Tq5okbBKMGyYVbuuzvpok+o/L+BWJnz11Wj06CuzZ9uFj4j9naRCaYqf1Bn0UaP8Ff0KFLbwJ5aAiPmzfAx3lQ5C9kurY9MKKJezhZ46O+0X6l13Jdd/XuDyy73jd95JbqbLlVfaUtG/+lXy35daJ1UGvbGxa2MeuIU/iYkWa7gAABLFSURBVAREzCdJaWqiXaX/n4XHRKNfACtW2G44nZ02OB37jKIyaG21/uZSrrkmGl16Sy4HZ59tG17ff3/U2iiVIDUGvbGx6xzzMWPitYW/zzgR80UL3ebUwpYt8Vkxuv7ypPvPC7hpsElzu6xYYStFdHTY32l5X2qZZBn09uBysd0Z8wkTUrIyDyIfMc98cRKTJtVRbMRhiUtu9NNPe8crV0ajR6Vx87W76jIVV3bsKOpcqBahJJtkGPTt221Z2JEjbZnYknKxDXXtrFsX/ElKVFpiH1m0yAYcS/nOd6Jfpedy/jz/E06IRpdK49ZG37cvWaV03R2v7lhJHvE36OvX2xzsefOs83X3bti5E3bvRrZtocMEp+WNGZOwtMQ+ksnAr39td72W8ulPR6NPgRUr/F80ixZFokrFCero89hj4evRW9wURU1ZTD7xNuj5Bqu8/bavjZNwAKg/OLLYlfrMmSl2s3RDJmODj6Vs2hSNLgVmzLDpcHV1NpV+8eL0ZFI0N9v/tVKSVnmxsdG6JRcvjnEdI6Vs4m3Q8w1WS52TOaZ1a8wXL66tlblLUB2OKBtKZzJw3XXWzXLTTekzGm4+/ZAhkahxyGSzNlVx7dr09EVV4mzQAxqs5pjGGTxFV8Z81mGP0Dyn9w1W08ANN/hld90Vvh4FsllYsAA2bLC/k+RjLgc3kPjDH0ajx6Hi1kB3m48oySS+Bt1psAqwghlYlSX/U0zVm8t82g6/KjblYqOitdWzkRSwO2ajCo66hiJJPuZycAOJ69bZshNxJpv1uyTd5iNKMomvQXcarALMYAV2V2RpznUHz3AGrdwaq3KxUfI3f+OXRZHCmMvBKqcRYdoCb0HXE/cvraAORUnr7aoEE1+DHtBgNcNKnuEsRvMH6mlnCjkMh5Ehn9gco3KxUbJsGRxxhFcWhZFZsMC+JQUmTUqfD7252V//LO756K6baODA9ASqa534GvQuGqxmWMmbjKWdfvk6JiXErFxslLhdZ7ZuDd9/7W4gCiqWlgaOOso7PvLIaPQol7FjveMTT4xEDaUKxNegR9FgNUVccIFfdvvt4Z0/m/XX1Rk/Przzh4kbs3AybGNHIhq6KL0ivgYdAsvFBiISu3KxUdPWZjtclbJxY3jB0SAXT1r9tO7Gqffei282Ty5n9+qV8qc/RaOLUnnibdBDbrCaNu64wy9bsCCcc7vBwrlz0+unvfJKvyyuaYA33+yXuaWAleQSb4MOoTZYTRvNzX7/6OOPh7NKnzix6Mc/7DC4+OLqnzMqWlth9GivrFxPYdg8+6x3XFeX0GYvSiDxN+gQWoPVNBL0pwlapVWaJUuKzUQ6O9NfmnXy5Kg1KA9na0fsM3KUQyMZBr1AlRusppE5c/yyX/+6uufM5azLobQpdNJbzvXEyJHe8VNPRV/p0iXIrx/XOwmldyTLoCuHTHOzTRgqpbOzursZlyyxnYkKnH9+ev3nBWbP9sbujQkvXlEuQYHq664LXw+lepRl0EXkXBF5TUQ2iIjvhl1EbhKRtSLykoj8UkTGVF5Vpbd85jN+2aOPVu98bg16d/WaRjIZOPpoKO5gNqz89f5YN7EdM0b952mjR4MuIvXAQuA8oBG4TEQanWkvAJONMacAPwZitjapbdra/FUA9++vThXGbNYmHBWor6+RTvLbt9O55z2PaO+fdttvs9tus6WgI+b1171jd/OZknzKWaFPATYYY143xuwHHgYuKp1gjPmVMabw37wScGL+StQ88YRfdvfdlT+Pe1t/+unpd7cUmrCcsv95j/gUXrJNWebNszuf3QTwkJk61Tu+5JJo9FCqRzkG/VjgzZLxprysK+YAvwh6QkSaRWSViKzaunVr+VoqfSaT8e/P2rev8oE7t8FD2oOhpU1Y5pubqecAhQJyx/EHO2fvXpuhNX16ZCv1XA4eeaQ4njVL3S1ppKJBURFpAiYD3wx63hiTNcZMNsZMHjFiRCVPrZRBUEZDpVvUPfigd7x8eWWPHztKmrBkWMmlPEyhvPMD/E9ayNdbKHRhXrgwEjUXLPAGqnX7fzopx6BvBo4rGY/OyzyIyMeBfwAuNMbsc59Xoicoo2HTpsptU89m/S3vXL9tqghowrKcQk86ezv0fUq2ke7da/1cHeE3YXG/WF94IXQVlBAox6A/D4wTkeNFpB9wKbC0dIKInAYsxhrzdyqvplIJWlv9dUcguD72IdHeDi++yN3zdlPM8rAEFQlLDQFNWBrwGutOnL0S+/eH3oSlqcnWlykl7hUhld7Ro0E3xrQD1wLLgHXAI8aYNSJym4hcmJ/2TWAg8KiIrBaRpV0cTomYyy7zyzb77rfKZPt2m8ExciSceSZb3igtM2jo37+dtrZeHjsJBDRhmYp3b/02jibHtKIggiYsvwiIaAW1KlSST1k+dGPME8aY8caYDxlj/ikv+5oxZmn+8ceNMccYYyblfy7s/ohKVLS1+TcaHTjQC7dLPrODefNg2zZyu09mO0d7ppzQviHyzI6qEtCEZS7fBDqwdyoC1LOArxQnRNCE5ZhjvOORI9PXaESx6E7RGuSmm/yy//W/DuEAJZkdBf/xNSyk2O/Vul1u7Lgz0syOqhPQhCXDSgazyyN7krOKgwiasLz5pnfsfqEr6UENeg3S2uov2rVrF5xzTpkHKMnsAMgxjdV48xUHsIdm7os0s6PqdNGEpd3xm+9ioH0QQROWlhbYvdsrO+GE0E6vhIwa9BolKBC6fHkZeekBmR03M49Cql6BD/C2fRBhZkcoBDRh+R88nn9kv/AOcDhZroqkCct99/ll8+eHqoISImrQa5TmZn8Nb4DzzuvhhQGZHS9wWsnIGrFbKLEaEWR2hEZAE5Y2rmDAQbeLNfS3190abhOWfObRuzsL/nxLfX0N7NytYdSg1zClOwcL7NzZw4sCMjt24e11J3TQzL8WBRFkdoRKQBOWfk764vYBHwynCUtJ5lEucxMdnaXbgw31dZ3V10GJDDXoNUxQOQDwd4X34GR2TOVpSl0tgUSQ2RE6ThOWU04tfVLYtbuu+vXRncyjJe9/CtcV1tj5Srozj2ocNeg1TlA/yY0bu6mX7mR2PEeh4lMxu+Uvec77mggyOyIj34Rl/rePxv2iq2qnqIDMIy8G6GRRxxfSnXlU46hBr3Ha2nyZdwA89FAXLyjJ7Gjiftx/oTraeZaPFQURZHbEgUwG3HJFVS2D4GQeAfy/g++DlU3hWTLk0p15VOOoQVe45x6/rLOzmzTGa68lN+BsHqCwjC+uzr/NNcV5IpFkdsSFK6/0jgcNCp7XZwIyj7J8nnVMzI/sncKr5NsYpD3zqIZRg67Q3AwzZ/rly5d34XoZOpTzDzyO658dx2+LwdDDD7eZH2FmdsSM1laYMKE4XreuSq3/AjKP7qKwt7/4/pxAyS1CmjOPahg16AoAy5bBgAF++QMP+IOkjY2wY1fpdkMDGO4/8lq7DB0+3GZ8rFkTTmZHjHn7be84qK5KnwnIPHqf0jfTvj+LKLlTSnvmUY2im4CVg3zrW3D11X75xo3B2TClq79Zn9hBpuVrNpvl5JNrzmfeFccc440/unVVKkJATZkh7PCMJ7GaDCuLglrIPKpBdIWuHKS5GaZMOfTXDRkitP37UJtlceqpasxLKG0qAbYjXcVxMo9sKYZTPFOmOVUgayrzqIZQg654ePbZYH96dwT1K1Usbt/Od96pXEORgzg1ZT7Nw0A9xWB1B7NZUpxfo5lHtYAadMXHsmWweHF5c+fO1a3k3dHa6s9uOaTKluWSrymT5So28UHPU0fyftHdUuOZR2lHDboSSHMzPPOMP5e6wKhR1uhro+GeOeII73jXLlsFsaLka8rcVV+ojVxMJb2Yn1qRZh6lHjXoSpdkMtZFYIztEj90qP1tDPzxj9okoVw++1m/7Pvfr8KJxo3jncHerKIB7KZt0LWaeVQjaJaLUhapbiVXZVpb7T6e0lTxamQMZrOw7c9ev/jkU9vh/qc086hG0BW6ooSA21Ri377Ku11uucWVCI2ZozXzqIZQg64oIXDjjX5ZJd0uuVxwva3Zsyt3DiX+qEFXlBAIKq+wdWvlUhiXLAmWawZSbaEGXVFCYtkymx1Uyne/W5ljr1zpl5XWkVFqAzXoihIiboLJ73/f92O2tMDq1V7ZyJGwdm3fj60kCzXoihIijY3e8datfa/AuGiRX3b99X07ppJM1KArSogEBSkffbRvx3zvPb9sxoy+HVNJJmrQFSVEMhn/ztH9++l1v9GmJls4sZRx4zQYWquoQVeUkLnuOr/smmv8sp7I5Wy9epf77z/0YynpoCyDLiLnishrIrJBRHytbkWkv4j8KP/8syIyttKKKkpaaG2FSZO8stWrYerU4Pld8Xd/55dNmqSr81qmR4MuIvXAQuA8oBG4TESc0A5zgD8bY04EvgVoySZF6YagQOZzz5W/e3TqVNi8ubzjKrVDOSv0KcAGY8zrxpj9wMPARc6ci4DCjd6PgbNFgnvcKIpiV9FBTaMXLOj5tS0t1vi7aCljpRyDfizwZsl4U14WOMcY0w7sBIa5BxKRZhFZJSKrtm7d2juNFSUlfPGLwXK3h2spuVyw0R89WksZKyEHRY0xWWPMZGPM5BFdFdpWlBqhtTW4ZtbGjXDOOcGvmT49WP7II5XTS0ku5Rj0zcBxJePReVngHBFpAI4CqtE9UVFSRVc+7+XL4aijirVepk61zYba2/1zZ85UV4tiKcegPw+ME5HjRaQfcCmw1JmzFLgi//hTwH8ZY0zl1FSUdNLcbH3fQbz7Llx9tTXkQT5zsFv8ly2rnn5KsujRoOd94tcCy4B1wCPGmDUicpuIXJif9l1gmIhsAG4CfKmNiqIE09pqO0EdKgMGwFtvVV4fJbmU1bHIGPME8IQj+1rJ471AQFasoijl0NYGxx7r72zUFYcdBnv2VF8vJVnoTlFFiQmtrbB3L4wZ0/28kSNtuQBFcVGDrigx4403/M0wAAYPhsWL1c2idI02iVaUGKKBTqU36ApdURQlJahBVxRFSQlq0BVFUVKCGnRFUZSUoAZdURQlJahBVxRFSQkSVckVEdkKbOzly4cDf6qgOklAr7k20GuuDfpyzWOMMYHlaiMz6H1BRFYZYyZHrUeY6DXXBnrNtUG1rlldLoqiKClBDbqiKEpKSKpBz0atQAToNdcGes21QVWuOZE+dEVRFMVPUlfoiqIoioMadEVRlJQQa4MuIueKyGsiskFEfG3tRKS/iPwo//yzIjI2fC0rSxnXfJOIrBWRl0TklyLSQzuE+NPTNZfM+6SIGBFJfIpbOdcsIp/Ov9drROTBsHWsNGX8b39QRH4lIi/k/7/Pj0LPSiEi3xORd0TklS6eFxG5J//3eElEPtrnkxpjYvkD1AO/A04A+gEvAo3OnGuA7+QfXwr8KGq9Q7jmvwYG5B9/sRauOT9vEPAksBKYHLXeIbzP44AXgKPz4w9ErXcI15wFvph/3Ai8EbXefbzm6cBHgVe6eP584BeAANOAZ/t6zjiv0KcAG4wxrxtj9gMPAxc5cy4C7s8//jFwtohIiDpWmh6v2RjzK2PMe/nhSmB0yDpWmnLeZ4B/BFqBvWEqVyXKueargIXGmD8DGGPeCVnHSlPONRtgcP7xUcAfQ9Sv4hhjngS2dzPlImCJsawEhojIqL6cM84G/VjgzZLxprwscI4xph3YCQwLRbvqUM41lzIH+w2fZHq85vyt6HHGmJ+HqVgVKed9Hg+MF5GnRWSliJwbmnbVoZxr/jrQJCKbsE3prwtHtcg41M97j2gLuoQiIk3AZOCvotalmohIHXAn8NmIVQmbBqzbZQb2LuxJEZlojNkRqVbV5TLgB8aYfxaRDPBDETnZGNMZtWJJIc4r9M3AcSXj0XlZ4BwRacDepm0LRbvqUM41IyIfB/4BuNAYsy8k3apFT9c8CDgZWCEib2B9jUsTHhgt533eBCw1xhwwxvwe+C3WwCeVcq55DvAIgDEmBxyOLWKVVsr6vB8KcTbozwPjROR4EemHDXoudeYsBa7IP/4U8F8mH21IKD1es4icBizGGvOk+1Whh2s2xuw0xgw3xow1xozFxg0uNMasikbdilDO//bj2NU5IjIc64J5PUwlK0w51/wH4GwAEZmANehbQ9UyXJYCs/PZLtOAncaYt/p0xKgjwT1Eic/Hrkx+B/xDXnYb9gMN9g1/FNgAPAecELXOIVzzfwJvA6vzP0uj1rna1+zMXUHCs1zKfJ8F62paC7wMXBq1ziFccyPwNDYDZjUwM2qd+3i9DwFvAQewd1xzgC8AXyh5jxfm/x4vV+L/Wrf+K4qipIQ4u1wURVGUQ0ANuqIoSkpQg64oipIS1KAriqKkBDXoiqIoKUENuqIoSkpQg64oipIS/j9BQW8eFkxJagAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as utils\n",
        "#import pytorch_ssim\n",
        "import  time \n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.nn.modules.loss import _Loss \n",
        "#from net.Ushape_Trans import *\n",
        "#from dataset import prepare_data, Dataset\n",
        "#from net.utils import *\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#from utility import plots as plots, ptcolor as ptcolor, ptutils as ptutils, data as data\n",
        "#from loss.LAB import *\n",
        "#from loss.LCH import *"
      ],
      "metadata": {
        "id": "eFvSqrR-IhWB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
      ],
      "metadata": {
        "id": "DS3j1o-LO_Ij"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(img):\n",
        "    output=[]\n",
        "    output.append(F.interpolate(img, scale_factor=0.125))\n",
        "    output.append(F.interpolate(img, scale_factor=0.25))\n",
        "    output.append(F.interpolate(img, scale_factor=0.5))\n",
        "    output.append(img)\n",
        "    return output"
      ],
      "metadata": {
        "id": "Jk6vqjCPPCEK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = 'float32'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "torch.set_default_tensor_type(torch.FloatTensor)"
      ],
      "metadata": {
        "id": "x8m_AABXPF96"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize generator \n",
        "generator = Generator().cuda()\n",
        "generator.load_state_dict(torch.load(\"/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/saved_models/G/generator_795.pth\"))"
      ],
      "metadata": {
        "id": "5jXC4k92UhfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94fac18a-8ec6-4e0f-ba7c-4ddda32db723"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_x=[]\n",
        "path='/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/input/'\n",
        "path_list = os.listdir(path)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "for item in path_list:\n",
        "    impath=path+item\n",
        "    #print(\"image path is \"+impath)\n",
        "    imgx= cv2.imread(impath)\n",
        "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
        "    imgx=cv2.resize(imgx,(256,256))\n",
        "    training_x.append(imgx)   \n",
        "\n",
        "X_train = []\n",
        "\n",
        "for features in training_x:\n",
        "    X_train.append(features)\n",
        "\n",
        "X_train = np.array(X_train)    "
      ],
      "metadata": {
        "id": "CuigyBsaPHI6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train.astype(dtype)\n",
        "X_train= torch.from_numpy(X_train)\n",
        "X_train=X_train.permute(0,3,1,2)"
      ],
      "metadata": {
        "id": "9_8n3g95PPot"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train/255.0\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "Zsjg_1M2QVrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0135b80-6c25-4951-cf3c-b17958433fbc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([108, 3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_y=[]\n",
        "path='/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/input/'\n",
        "path_list = os.listdir(path)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "for item in path_list:\n",
        "    impath=path+item\n",
        "    imgx= cv2.imread(path+item)\n",
        "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
        "    imgx=cv2.resize(imgx,(256,256))\n",
        "    training_y.append(imgx)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "y_train = []\n",
        "\n",
        "for features in training_y:\n",
        "    y_train.append(features)\n",
        "    \n",
        "\n",
        "    \n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "UEfe2nXYQZjd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.astype(dtype)\n",
        "y_train= torch.from_numpy(y_train)\n",
        "y_train=y_train.permute(0,3,1,2)"
      ],
      "metadata": {
        "id": "mY1xsPU5Qbxr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train/255.0\n",
        "y_train.shape"
      ],
      "metadata": {
        "id": "F4fX5jKLQd87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f65f05-571f-4b57-b348-cd7328dcec0e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([108, 3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x=[]\n",
        "path='/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/input/'\n",
        "path_list = os.listdir(path)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "for item in path_list:\n",
        "    impath=path+item\n",
        "    imgx= cv2.imread(path+item)\n",
        "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
        "    imgx=cv2.resize(imgx,(256,256))\n",
        "    test_x.append(imgx)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "x_test = []\n",
        "\n",
        "for features in test_x:\n",
        "    x_test.append(features)\n",
        "    \n",
        "\n",
        "    \n",
        "x_test = np.array(x_test)"
      ],
      "metadata": {
        "id": "lPmylU2lQgDi"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=x_test.astype(dtype)\n",
        "x_test= torch.from_numpy(x_test)\n",
        "x_test=x_test.permute(0,3,1,2)"
      ],
      "metadata": {
        "id": "89neL46KQiFy"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=x_test/255.0"
      ],
      "metadata": {
        "id": "sfN6bygcQj1L"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "id": "TPdFjIadQl66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698e8246-6311-4a75-907e-3b7030e0705e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([108, 3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as utils\n",
        "#import pytorch_ssim\n",
        "import  time \n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.nn.modules.loss import _Loss \n",
        "#from net.Ushape_Trans import *\n",
        "#from dataset import prepare_data, Dataset\n",
        "#from net.utils import *\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#from utility import plots as plots, ptcolor as ptcolor, ptutils as ptutils, data as data\n",
        "#from loss.LAB import *\n",
        "#from loss.LCH import *\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "xXPQfAXOOy9b"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
      ],
      "metadata": {
        "id": "GZHhbVNHOX59"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(img):\n",
        "    output=[]\n",
        "    output.append(F.interpolate(img, scale_factor=0.125))\n",
        "    output.append(F.interpolate(img, scale_factor=0.25))\n",
        "    output.append(F.interpolate(img, scale_factor=0.5))\n",
        "    output.append(img)\n",
        "    return output"
      ],
      "metadata": {
        "id": "WsfeV6WoOdrZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = 'float32'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "torch.set_default_tensor_type(torch.FloatTensor)"
      ],
      "metadata": {
        "id": "fL_2ozTGOgwQ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize generator \n",
        "generator = Generator().cuda()\n",
        "generator.load_state_dict(torch.load(\"/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/saved_models/G/generator_795.pth\"))"
      ],
      "metadata": {
        "id": "LBjtG0o3YIIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad00c019-626c-4368-fbaa-17d633631b9b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.eval()"
      ],
      "metadata": {
        "id": "uHHUwKatYTE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf24922-3785-43fa-cb6e-e5ea429f17f8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (linear_encoding): Linear(in_features=384, out_features=512, bias=True)\n",
              "  (position_encoding): LearnedPositionalEncoding()\n",
              "  (pe_dropout): Dropout(p=0.0, inplace=False)\n",
              "  (transformer): TransformerModel(\n",
              "    (net): IntermediateSequential(\n",
              "      (0): Residual(\n",
              "        (fn): PreNormDrop(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (fn): SelfAttention(\n",
              "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNormDrop(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (fn): SelfAttention(\n",
              "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): Residual(\n",
              "        (fn): PreNormDrop(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (fn): SelfAttention(\n",
              "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): Residual(\n",
              "        (fn): PreNormDrop(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (fn): SelfAttention(\n",
              "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fn): FeedForward(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "              (1): GELU(approximate=none)\n",
              "              (2): Dropout(p=0.0, inplace=False)\n",
              "              (3): Linear(in_features=256, out_features=512, bias=True)\n",
              "              (4): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_head_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Conv_x): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (rgb_to_feature): ModuleList(\n",
              "    (0): from_rgb(\n",
              "      (conv_1): _equalized_conv2d(32, 3, 1, 1)\n",
              "      (pixNorm): PixelwiseNorm()\n",
              "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (1): from_rgb(\n",
              "      (conv_1): _equalized_conv2d(64, 3, 1, 1)\n",
              "      (pixNorm): PixelwiseNorm()\n",
              "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (2): from_rgb(\n",
              "      (conv_1): _equalized_conv2d(128, 3, 1, 1)\n",
              "      (pixNorm): PixelwiseNorm()\n",
              "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "  )\n",
              "  (feature_to_rgb): ModuleList(\n",
              "    (0): to_rgb(\n",
              "      (conv_1): _equalized_conv2d(3, 32, 1, 1)\n",
              "    )\n",
              "    (1): to_rgb(\n",
              "      (conv_1): _equalized_conv2d(3, 64, 1, 1)\n",
              "    )\n",
              "    (2): to_rgb(\n",
              "      (conv_1): _equalized_conv2d(3, 128, 1, 1)\n",
              "    )\n",
              "    (3): to_rgb(\n",
              "      (conv_1): _equalized_conv2d(3, 256, 1, 1)\n",
              "    )\n",
              "  )\n",
              "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(16, 3, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(16, 16, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(16, 16, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv1_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(32, 16, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv2): conv_block(\n",
              "    (conv_1): _equalized_conv2d(32, 32, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv2_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(64, 32, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv3): conv_block(\n",
              "    (conv_1): _equalized_conv2d(64, 64, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv3_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(128, 64, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv4): conv_block(\n",
              "    (conv_1): _equalized_conv2d(128, 128, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv4_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(256, 128, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv5): conv_block(\n",
              "    (conv_1): _equalized_conv2d(256, 512, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (mtc): ChannelTransformer(\n",
              "    (embeddings_1): Channel_Embeddings(\n",
              "      (patch_embeddings): Conv2d(32, 32, kernel_size=(32, 32), stride=(32, 32))\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (embeddings_2): Channel_Embeddings(\n",
              "      (patch_embeddings): Conv2d(64, 64, kernel_size=(16, 16), stride=(16, 16))\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (embeddings_3): Channel_Embeddings(\n",
              "      (patch_embeddings): Conv2d(128, 128, kernel_size=(8, 8), stride=(8, 8))\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (embeddings_4): Channel_Embeddings(\n",
              "      (patch_embeddings): Conv2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): Block_ViT(\n",
              "          (attn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm): LayerNorm((480,), eps=1e-06, elementwise_affine=True)\n",
              "          (channel_attn): Attention_org(\n",
              "            (query1): ModuleList(\n",
              "              (0): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (1): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (2): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (3): Linear(in_features=32, out_features=32, bias=False)\n",
              "            )\n",
              "            (query2): ModuleList(\n",
              "              (0): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (1): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (2): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (3): Linear(in_features=64, out_features=64, bias=False)\n",
              "            )\n",
              "            (query3): ModuleList(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            )\n",
              "            (query4): ModuleList(\n",
              "              (0): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (1): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (2): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (3): Linear(in_features=256, out_features=256, bias=False)\n",
              "            )\n",
              "            (key): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (value): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (psi): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "            (softmax): Softmax(dim=3)\n",
              "            (out1): Linear(in_features=32, out_features=32, bias=False)\n",
              "            (out2): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (out3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            (out4): Linear(in_features=256, out_features=256, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ffn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn1): Mlp(\n",
              "            (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
              "            (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn2): Mlp(\n",
              "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
              "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn3): Mlp(\n",
              "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn4): Mlp(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): Block_ViT(\n",
              "          (attn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm): LayerNorm((480,), eps=1e-06, elementwise_affine=True)\n",
              "          (channel_attn): Attention_org(\n",
              "            (query1): ModuleList(\n",
              "              (0): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (1): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (2): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (3): Linear(in_features=32, out_features=32, bias=False)\n",
              "            )\n",
              "            (query2): ModuleList(\n",
              "              (0): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (1): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (2): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (3): Linear(in_features=64, out_features=64, bias=False)\n",
              "            )\n",
              "            (query3): ModuleList(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            )\n",
              "            (query4): ModuleList(\n",
              "              (0): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (1): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (2): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (3): Linear(in_features=256, out_features=256, bias=False)\n",
              "            )\n",
              "            (key): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (value): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (psi): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "            (softmax): Softmax(dim=3)\n",
              "            (out1): Linear(in_features=32, out_features=32, bias=False)\n",
              "            (out2): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (out3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            (out4): Linear(in_features=256, out_features=256, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ffn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn1): Mlp(\n",
              "            (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
              "            (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn2): Mlp(\n",
              "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
              "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn3): Mlp(\n",
              "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn4): Mlp(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): Block_ViT(\n",
              "          (attn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm): LayerNorm((480,), eps=1e-06, elementwise_affine=True)\n",
              "          (channel_attn): Attention_org(\n",
              "            (query1): ModuleList(\n",
              "              (0): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (1): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (2): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (3): Linear(in_features=32, out_features=32, bias=False)\n",
              "            )\n",
              "            (query2): ModuleList(\n",
              "              (0): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (1): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (2): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (3): Linear(in_features=64, out_features=64, bias=False)\n",
              "            )\n",
              "            (query3): ModuleList(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            )\n",
              "            (query4): ModuleList(\n",
              "              (0): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (1): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (2): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (3): Linear(in_features=256, out_features=256, bias=False)\n",
              "            )\n",
              "            (key): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (value): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (psi): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "            (softmax): Softmax(dim=3)\n",
              "            (out1): Linear(in_features=32, out_features=32, bias=False)\n",
              "            (out2): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (out3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            (out4): Linear(in_features=256, out_features=256, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ffn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn1): Mlp(\n",
              "            (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
              "            (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn2): Mlp(\n",
              "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
              "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn3): Mlp(\n",
              "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn4): Mlp(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): Block_ViT(\n",
              "          (attn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn_norm): LayerNorm((480,), eps=1e-06, elementwise_affine=True)\n",
              "          (channel_attn): Attention_org(\n",
              "            (query1): ModuleList(\n",
              "              (0): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (1): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (2): Linear(in_features=32, out_features=32, bias=False)\n",
              "              (3): Linear(in_features=32, out_features=32, bias=False)\n",
              "            )\n",
              "            (query2): ModuleList(\n",
              "              (0): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (1): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (2): Linear(in_features=64, out_features=64, bias=False)\n",
              "              (3): Linear(in_features=64, out_features=64, bias=False)\n",
              "            )\n",
              "            (query3): ModuleList(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            )\n",
              "            (query4): ModuleList(\n",
              "              (0): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (1): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (2): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (3): Linear(in_features=256, out_features=256, bias=False)\n",
              "            )\n",
              "            (key): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (value): ModuleList(\n",
              "              (0): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (1): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (2): Linear(in_features=480, out_features=480, bias=False)\n",
              "              (3): Linear(in_features=480, out_features=480, bias=False)\n",
              "            )\n",
              "            (psi): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "            (softmax): Softmax(dim=3)\n",
              "            (out1): Linear(in_features=32, out_features=32, bias=False)\n",
              "            (out2): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (out3): Linear(in_features=128, out_features=128, bias=False)\n",
              "            (out4): Linear(in_features=256, out_features=256, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ffn_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (ffn1): Mlp(\n",
              "            (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
              "            (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn2): Mlp(\n",
              "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
              "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn3): Mlp(\n",
              "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ffn4): Mlp(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (act_fn): GELU(approximate=none)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (encoder_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "      (encoder_norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
              "      (encoder_norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "      (encoder_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "    (reconstruct_1): Reconstruct(\n",
              "      (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (reconstruct_2): Reconstruct(\n",
              "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (reconstruct_3): Reconstruct(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (reconstruct_4): Reconstruct(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activation): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Up5): up_conv(\n",
              "    (conv_1): _equalized_conv2d(256, 256, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (coatt5): CCA(\n",
              "    (mlp_x): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (mlp_g): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (Up_conv5): conv_block(\n",
              "    (conv_1): _equalized_conv2d(256, 512, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up_conv5_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(256, 256, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(256, 256, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up4): up_conv(\n",
              "    (conv_1): _equalized_conv2d(128, 256, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (coatt4): CCA(\n",
              "    (mlp_x): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (mlp_g): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (Up_conv4): conv_block(\n",
              "    (conv_1): _equalized_conv2d(128, 256, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up_conv4_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(128, 128, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(128, 128, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up3): up_conv(\n",
              "    (conv_1): _equalized_conv2d(64, 128, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (coatt3): CCA(\n",
              "    (mlp_x): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
              "    )\n",
              "    (mlp_g): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
              "    )\n",
              "    (relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (Up_conv3): conv_block(\n",
              "    (conv_1): _equalized_conv2d(64, 128, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up_conv3_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(64, 64, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(64, 64, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up2): up_conv(\n",
              "    (conv_1): _equalized_conv2d(32, 64, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (coatt2): CCA(\n",
              "    (mlp_x): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
              "    )\n",
              "    (mlp_g): Sequential(\n",
              "      (0): Flatten()\n",
              "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
              "    )\n",
              "    (relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (Up_conv2): conv_block(\n",
              "    (conv_1): _equalized_conv2d(32, 64, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Up_conv2_1): conv_block(\n",
              "    (conv_1): _equalized_conv2d(32, 32, 1, 1)\n",
              "    (conv_2): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (conv_3): _equalized_conv2d(32, 32, 3, 3)\n",
              "    (pixNorm): PixelwiseNorm()\n",
              "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Conv): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/input/'\n",
        "path_list = os.listdir(path)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "i=1\n",
        "for item in path_list:\n",
        "    impath=path+item\n",
        "    imgx= cv2.imread(path+item)\n",
        "    imgx=cv2.resize(imgx,(256,256))\n",
        "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
        "    imgx = np.array(imgx).astype(dtype)\n",
        "\n",
        "    imgx= torch.from_numpy(imgx)\n",
        "    imgx=imgx.permute(2,0,1).unsqueeze(0)\n",
        "    imgx=imgx/255.0\n",
        "    #plt.imshow(imgx[0,:,:,:])\n",
        "    #plt.show()\n",
        "    imgx = Variable(imgx).cuda()\n",
        "    #print(imgx.shape)\n",
        "    output=generator(imgx)\n",
        "    out=output[3].data\n",
        "    save_image(out, \"/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/output\"+item, nrow=5, normalize=True)\n",
        "    i=i+1"
      ],
      "metadata": {
        "id": "1Otblm9ZPCBj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_psnr(img1, img2):\n",
        "   mse = np.mean( (img1/255. - img2/255.) ** 2 )\n",
        "   if mse < 1.0e-10:\n",
        "      return 100\n",
        "   PIXEL_MAX = 1\n",
        "   return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
        "def compute_mse(img1,img2):\n",
        "    mse=np.mean( (img1/255. - img2/255.) ** 2 )\n",
        "    return mse"
      ],
      "metadata": {
        "id": "SMuKBZU8PQ_2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path1='/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/GT/'\n",
        "path2='/content/drive/MyDrive/U-shape_Transformer_for_Underwater_Image_Enhancement-main/test/output'\n",
        "path_list = os.listdir(path1)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "PSNR=[]\n",
        "\n",
        "for item in path_list:\n",
        "    impath1=path1+item\n",
        "    impath2=path2+item\n",
        "    imgx= cv2.imread(impath1)\n",
        "    imgx=cv2.resize(imgx,(256,256))\n",
        "    imgy= cv2.imread(impath2)\n",
        "    imgy=cv2.resize(imgy,(256,256))\n",
        "    #print(imgx.shape)\n",
        "    psnr1=compute_psnr(imgx[:,:,0],imgy[:,:,0])\n",
        "    psnr2=compute_psnr(imgx[:,:,1],imgy[:,:,1])\n",
        "    psnr3=compute_psnr(imgx[:,:,2],imgy[:,:,2])\n",
        "    \n",
        "\n",
        "    psnr=(psnr1+psnr2+psnr3)/3.0\n",
        "\n",
        "    PSNR.append(psnr)"
      ],
      "metadata": {
        "id": "N0T2Ia5OPUNf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PSNR=np.array(PSNR)    \n",
        "print(PSNR.mean())"
      ],
      "metadata": {
        "id": "EoDZ2hc_ZGG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f10f58-1124-4175-c3b8-be85abb7c98c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24.750264664730544\n"
          ]
        }
      ]
    }
  ]
}